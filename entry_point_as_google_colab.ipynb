{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2kscaZ2lqm1R",
        "outputId": "c5424148-6b5c-4a4f-8645-02b7fd66d916"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.12/dist-packages (0.25.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Collecting datasets>=3.0.0 (from trl)\n",
            "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Collecting pyarrow>=21.0.0 (from datasets>=3.0.0->trl)\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.28.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=3.0.0->trl) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets>=3.0.0->trl) (1.3.1)\n",
            "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarrow, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.21.0\n",
            "    Uninstalling datasets-2.21.0:\n",
            "      Successfully uninstalled datasets-2.21.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-4.4.1 pyarrow-22.0.0\n",
            "Collecting datasets==2.21.0\n",
            "  Using cached datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (22.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets==2.21.0) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (3.13.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (6.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.21.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.21.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.21.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.21.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.21.0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.21.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.21.0) (1.22.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.2->datasets==2.21.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.2->datasets==2.21.0) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==2.21.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==2.21.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==2.21.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==2.21.0) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.21.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.21.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.21.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.21.0) (1.17.0)\n",
            "Using cached datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "Installing collected packages: datasets\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.4.1\n",
            "    Uninstalling datasets-4.4.1:\n",
            "      Successfully uninstalled datasets-4.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "trl 0.25.1 requires datasets>=3.0.0, but you have datasets 2.21.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.21.0\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (6.0.3)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.22.3)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.11.10)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.43.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.10.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: uv in /usr/local/lib/python3.12/dist-packages (0.9.8)\n",
            "\u001b[1m\u001b[31merror\u001b[39m\u001b[0m: Project is already initialized in `\u001b[36m/content\u001b[39m` (`pyproject.toml` file exists)\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m87 packages\u001b[0m \u001b[2min 43ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m7 packages\u001b[0m \u001b[2min 46.80s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m85 packages\u001b[0m \u001b[2min 252ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mabsl-py\u001b[0m\u001b[2m==2.3.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.11.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1maiohappyeyeballs\u001b[0m\u001b[2m==2.6.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1maiohttp\u001b[0m\u001b[2m==3.13.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1maiosignal\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.11.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mattrs\u001b[0m\u001b[2m==25.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.11.12\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdill\u001b[0m\u001b[2m==0.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mevaluate\u001b[0m\u001b[2m==0.4.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfrozenlist\u001b[0m\u001b[2m==1.8.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.10.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgitdb\u001b[0m\u001b[2m==4.0.12\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgitpython\u001b[0m\u001b[2m==3.1.45\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mh11\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhf-xet\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhttpcore\u001b[0m\u001b[2m==1.0.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.36.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.11\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.5.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmultidict\u001b[0m\u001b[2m==6.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmultiprocess\u001b[0m\u001b[2m==0.70.18\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnltk\u001b[0m\u001b[2m==3.9.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.3.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.8.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.10.2.21\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.3.83\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.13.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.9.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.3.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.27.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvshmem-cu12\u001b[0m\u001b[2m==3.3.20\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==25.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.3.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpeft\u001b[0m\u001b[2m==0.17.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mplatformdirs\u001b[0m\u001b[2m==4.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpropcache\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==6.33.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==7.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyarrow\u001b[0m\u001b[2m==22.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.12.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.41.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-dateutil\u001b[0m\u001b[2m==2.9.0.post0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2025.11.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrouge-score\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msafetensors\u001b[0m\u001b[2m==0.6.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msentry-sdk\u001b[0m\u001b[2m==2.44.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==80.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msix\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msmmap\u001b[0m\u001b[2m==5.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msniffio\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.22.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.9.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.57.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.5.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtrl\u001b[0m\u001b[2m==0.25.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.15.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwandb\u001b[0m\u001b[2m==0.23.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mxxhash\u001b[0m\u001b[2m==3.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1myarl\u001b[0m\u001b[2m==1.22.0\u001b[0m\n",
            "\u001b[2mResolved \u001b[1m87 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_552c8a06-f8c8-4346-a12a-f5e48ea81620\", \"pyproject.toml\", 440)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1ebd8178-8cc3-4553-8e5b-ab9793dbdc7f\", \"uv.lock\", 375318)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --upgrade accelerate transformers trl evaluate rouge_score peft\n",
        "!pip install datasets==2.21.0\n",
        "!pip install pyyaml wandb\n",
        "!pip freeze > requirements.txt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install uv\n",
        "\n",
        "!uv init --name kyivstar-llm-summarization --no-readme\n",
        "\n",
        "!uv add torch transformers datasets accelerate peft trl numpy pandas pyyaml tqdm wandb evaluate rouge-score\n",
        "\n",
        "!uv lock\n",
        "\n",
        "from google.colab import files\n",
        "files.download('pyproject.toml')\n",
        "files.download('uv.lock')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/kyivstar-test-task.zip'\n",
        "\n",
        "extract_path = '/content/project'\n",
        "\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "print(f\"Распаковываем архив из {zip_path}...\")\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"Архив распакован в {extract_path}\")\n",
        "\n",
        "print(\"\\nСодержимое /content/project:\")\n",
        "!ls -la /content/project\n",
        "\n",
        "print(\"\\nДерево директорий:\")\n",
        "!find /content/project -maxdepth 2 -type d\n",
        "\n",
        "print(\"\\nИщем config.yaml:\")\n",
        "!find /content/project -name \"config.yaml\"\n",
        "\n",
        "print(\"\\nИщем Python файлы проекта:\")\n",
        "!find /content/project -name \"entry_point.py\"\n",
        "!find /content/project -name \"data_preparation_and_generation.py\""
      ],
      "metadata": {
        "id": "R9plpYtPqo6A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ad3c2e-bda4-45b8-da76-b08244120711"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Распаковываем архив из /content/drive/MyDrive/kyivstar-test-task.zip...\n",
            "Архив распакован в /content/project\n",
            "\n",
            "Содержимое /content/project:\n",
            "total 12\n",
            "drwxr-xr-x  3 root root 4096 Nov 12 17:05 .\n",
            "drwxr-xr-x  1 root root 4096 Nov 12 17:05 ..\n",
            "drwxr-xr-x 13 root root 4096 Nov 12 17:08 kyivstar-test-task\n",
            "\n",
            "Дерево директорий:\n",
            "/content/project\n",
            "/content/project/kyivstar-test-task\n",
            "/content/project/kyivstar-test-task/outputs\n",
            "/content/project/kyivstar-test-task/checkpoints\n",
            "/content/project/kyivstar-test-task/sft_output\n",
            "/content/project/kyivstar-test-task/media\n",
            "/content/project/kyivstar-test-task/models\n",
            "/content/project/kyivstar-test-task/llm_summarize\n",
            "/content/project/kyivstar-test-task/notebooks\n",
            "/content/project/kyivstar-test-task/scripts\n",
            "/content/project/kyivstar-test-task/data\n",
            "/content/project/kyivstar-test-task/config\n",
            "/content/project/kyivstar-test-task/grpo_output\n",
            "\n",
            "Ищем config.yaml:\n",
            "/content/project/kyivstar-test-task/config/config.yaml\n",
            "\n",
            "Ищем Python файлы проекта:\n",
            "/content/project/kyivstar-test-task/scripts/entry_point.py\n",
            "/content/project/kyivstar-test-task/llm_summarize/data_preparation_and_generation.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "import wandb\n",
        "from huggingface_hub import login\n",
        "\n",
        "hf_token = userdata.get('HF_ACSESS_TOKEN')\n",
        "wandb_key = userdata.get('WANDB_API_KEY')\n",
        "\n",
        "os.environ['HF_TOKEN'] = hf_token\n",
        "os.environ['WANDB_API_KEY'] = wandb_key\n",
        "\n",
        "login(token=hf_token)\n",
        "wandb.login(key=wandb_key)\n",
        "\n"
      ],
      "metadata": {
        "id": "S0jmiuTOqrKA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcf211e9-ef10-42a0-b008-80c030a28d29"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdmytro-stepanchuk-cs\u001b[0m (\u001b[33mdmytro-stepanchuk-cs-igor-sikorsky-kyiv-polytechnic-inst\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "with open('/content/project/kyivstar-test-task/config/config.yaml', 'r', encoding='utf-8') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "print(\"Конфигурация загружена:\")\n",
        "print(f\"  - Базовая модель: {config['models']['base_model']['name']}\")\n",
        "print(f\"  - Train samples: {config['dataset']['subset_sizes']['train']}\")\n",
        "print(f\"  - SFT epochs: {config['sft']['training']['num_train_epochs']}\")\n",
        "print(f\"  - GRPO epochs: {config['grpo']['training']['num_train_epochs']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vytEX5cDqs-0",
        "outputId": "dfd8ac7b-384e-4884-b88f-3a4b93b096e3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Конфигурация загружена:\n",
            "  - Базовая модель: google/gemma-3-1b-it\n",
            "  - Train samples: 10000\n",
            "  - SFT epochs: 1\n",
            "  - GRPO epochs: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "script_path = '/content/project/kyivstar-test-task/scripts/entry_point.py'\n",
        "\n",
        "process = subprocess.Popen(\n",
        "    [sys.executable, script_path, '--stages','data', 'sft'],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True,\n",
        "    bufsize=1,\n",
        "    cwd='/content/project/kyivstar-test-task'\n",
        ")\n",
        "\n",
        "for line in process.stdout:\n",
        "    print(line, end='')\n",
        "\n",
        "return_code = process.wait()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "if return_code != 0:\n",
        "    print(f\"❌ Ошибка! Return code: {return_code}\")"
      ],
      "metadata": {
        "id": "t6g-MBfMqtBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "script_path = '/content/project/kyivstar-test-task/scripts/entry_point.py'\n",
        "\n",
        "\n",
        "\n",
        "process = subprocess.Popen(\n",
        "    [sys.executable, script_path, '--full', '--stages', 'grpo'],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True,\n",
        "    bufsize=1,\n",
        "    cwd='/content/project/kyivstar-test-task'\n",
        ")\n",
        "\n",
        "for line in process.stdout:\n",
        "    print(line, end='')\n",
        "\n",
        "return_code = process.wait()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "if return_code != 0:\n",
        "    print(f\"❌ Ошибка! Return code: {return_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snprzb6eUMGe",
        "outputId": "8e5c6688-8910-487d-d230-1e42f83aa842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-12 09:25:55.680244: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-12 09:25:55.700602: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762939555.722572   23394 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762939555.729169   23394 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762939555.746380   23394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762939555.746408   23394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762939555.746410   23394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762939555.746412   23394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-12 09:25:55.751445: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-11-12 09:26:02,300 - __main__ - INFO - Configuration loaded from config/config.yaml\n",
            "2025-11-12 09:26:02,301 - __main__ - INFO - Pipeline initialized\n",
            "2025-11-12 09:26:02,301 - __main__ - INFO - \n",
            "====================================================================================================\n",
            "2025-11-12 09:26:02,301 - __main__ - INFO - STARTING COMPLETE PIPELINE\n",
            "2025-11-12 09:26:02,301 - __main__ - INFO - Start time: 2025-11-12 09:26:02\n",
            "2025-11-12 09:26:02,301 - __main__ - INFO - ====================================================================================================\n",
            "\n",
            "2025-11-12 09:26:02,301 - __main__ - INFO - Skipping data preparation stage\n",
            "2025-11-12 09:26:02,301 - __main__ - INFO - Skipping SFT training stage\n",
            "2025-11-12 09:26:02,301 - __main__ - INFO - \n",
            "====================================================================================================\n",
            "2025-11-12 09:26:02,301 - __main__ - INFO - STAGE: GRPO ALIGNMENT\n",
            "2025-11-12 09:26:02,301 - __main__ - INFO - ====================================================================================================\n",
            "\n",
            "2025-11-12 09:26:02,312 - llm_summarize.grpo_alignment - INFO - Configuration loaded from config/config.yaml\n",
            "2025-11-12 09:26:02,312 - llm_summarize.grpo_alignment - INFO - GRPOAlignmentTrainer initialized successfully\n",
            "2025-11-12 09:26:02,312 - llm_summarize.grpo_alignment - INFO - \n",
            "================================================================================\n",
            "2025-11-12 09:26:02,312 - llm_summarize.grpo_alignment - INFO - GRPO ALIGNMENT PIPELINE\n",
            "2025-11-12 09:26:02,312 - llm_summarize.grpo_alignment - INFO - ================================================================================\n",
            "\n",
            "2025-11-12 09:26:02,312 - llm_summarize.grpo_alignment - INFO - Loading model and tokenizer...\n",
            "2025-11-12 09:26:04,236 - llm_summarize.grpo_alignment - INFO - Tokenizer loaded from models/sft_final\n",
            "2025-11-12 09:26:04,236 - llm_summarize.grpo_alignment - INFO - Padding side: left\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "2025-11-12 09:26:04,549 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "2025-11-12 09:26:05,576 - llm_summarize.grpo_alignment - INFO - Base model loaded: google/gemma-3-1b-it\n",
            "2025-11-12 09:26:05,995 - llm_summarize.grpo_alignment - INFO - SFT LoRA adapters loaded from models/sft_final\n",
            "2025-11-12 09:26:05,995 - llm_summarize.grpo_alignment - INFO - Model and tokenizer loaded successfully\n",
            "2025-11-12 09:26:05,995 - llm_summarize.grpo_alignment - INFO - Loading toxicity reward model...\n",
            "2025-11-12 09:26:06,202 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "Device set to use cuda:0\n",
            "2025-11-12 09:26:07,900 - llm_summarize.grpo_alignment - INFO - Toxicity classifier loaded: textdetox/xlmr-large-toxicity-classifier-v2\n",
            "2025-11-12 09:26:07,900 - llm_summarize.grpo_alignment - INFO - Loading datasets...\n",
            "2025-11-12 09:26:07,962 - llm_summarize.grpo_alignment - INFO - Loaded 713 training samples (toxic)\n",
            "2025-11-12 09:26:07,962 - llm_summarize.grpo_alignment - INFO - Loaded 152 validation samples (toxic)\n",
            "2025-11-12 09:26:08,841 - llm_summarize.grpo_alignment - INFO - Loaded 10000 clean training samples\n",
            "2025-11-12 09:26:08,841 - llm_summarize.grpo_alignment - INFO - Loaded 800 clean validation samples\n",
            "2025-11-12 09:26:08,978 - llm_summarize.grpo_alignment - INFO - Datasets formatted and ready for GRPO training\n",
            "2025-11-12 09:26:08,982 - llm_summarize.grpo_alignment - INFO - Starting GRPO alignment training...\n",
            "wandb: Currently logged in as: dmytro-stepanchuk-cs (dmytro-stepanchuk-cs-igor-sikorsky-kyiv-polytechnic-inst) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: setting up run gmisrgnr\n",
            "wandb: Tracking run with wandb version 0.22.3\n",
            "wandb: Run data is saved locally in /content/project/kyivstar-test-task/wandb/run-20251112_092609-gmisrgnr\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run gemma-3-1b-it-grpo-detox\n",
            "wandb: ⭐️ View project at https://wandb.ai/dmytro-stepanchuk-cs-igor-sikorsky-kyiv-polytechnic-inst/gemma-summarization-detox\n",
            "wandb: 🚀 View run at https://wandb.ai/dmytro-stepanchuk-cs-igor-sikorsky-kyiv-polytechnic-inst/gemma-summarization-detox/runs/gmisrgnr\n",
            "wandb: Detected [huggingface_hub.inference, openai] in use.\n",
            "wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
            "wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/\n",
            "2025-11-12 09:26:10,591 - llm_summarize.grpo_alignment - INFO - Weights & Biases initialized\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "2025-11-12 09:26:10,650 - llm_summarize.grpo_alignment - INFO - GRPOTrainer initialized\n",
            "2025-11-12 09:26:10,651 - llm_summarize.grpo_alignment - INFO - Training samples: 713\n",
            "2025-11-12 09:26:10,651 - llm_summarize.grpo_alignment - INFO - Evaluation samples: 152\n",
            "2025-11-12 09:26:10,651 - llm_summarize.grpo_alignment - INFO - Training epochs: 1\n",
            "2025-11-12 09:26:10,651 - llm_summarize.grpo_alignment - INFO - Generations per prompt: 4\n",
            "2025-11-12 09:26:10,651 - llm_summarize.grpo_alignment - INFO - \n",
            "================================================================================\n",
            "2025-11-12 09:26:10,652 - llm_summarize.grpo_alignment - INFO - STARTING GRPO ALIGNMENT\n",
            "2025-11-12 09:26:10,652 - llm_summarize.grpo_alignment - INFO - ================================================================================\n",
            "\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 1}.\n",
            "GRPOConfig(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=True,\n",
            "batch_eval_metrics=False,\n",
            "beta=0.0,\n",
            "bf16=True,\n",
            "bf16_full_eval=False,\n",
            "cache_implementation=None,\n",
            "cast_lm_head_to_fp32=False,\n",
            "chat_template_kwargs=None,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "delta=None,\n",
            "disable_dropout=False,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "ds3_gather_for_generation=True,\n",
            "epsilon=0.2,\n",
            "epsilon_high=None,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=IntervalStrategy.NO,\n",
            "eval_use_gather_object=False,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_batch_size=8,\n",
            "generation_kwargs=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "importance_sampling_level=token,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=no,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=1e-06,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_completions=False,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=trainer_output/runs/Nov12_09-26-10_a9fad9ea98ca,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=10,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "loss_type=dapo,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "mask_truncated_completions=False,\n",
            "max_completion_length=256,\n",
            "max_grad_norm=1.0,\n",
            "max_prompt_length=512,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "min_p=None,\n",
            "model_init_kwargs=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_completions_to_print=None,\n",
            "num_generations=8,\n",
            "num_iterations=1,\n",
            "num_train_epochs=3.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH_FUSED,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=trainer_output,\n",
            "overwrite_output_dir=False,\n",
            "parallelism_config=None,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "project=huggingface,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "ref_model_mixup_alpha=0.6,\n",
            "ref_model_sync_steps=512,\n",
            "remove_unused_columns=False,\n",
            "repetition_penalty=1.0,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "reward_weights=None,\n",
            "run_name=None,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "scale_rewards=group,\n",
            "seed=42,\n",
            "shuffle_dataset=True,\n",
            "skip_memory_metrics=True,\n",
            "steps_per_generation=1,\n",
            "sync_ref_model=False,\n",
            "temperature=1.0,\n",
            "tf32=None,\n",
            "top_entropy_quantile=1.0,\n",
            "top_k=None,\n",
            "top_p=1.0,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "trackio_space_id=trackio,\n",
            "use_cpu=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_liger_loss=None,\n",
            "use_mps_device=False,\n",
            "use_transformers_paged=False,\n",
            "use_vllm=False,\n",
            "vllm_enable_sleep_mode=False,\n",
            "vllm_gpu_memory_utilization=0.3,\n",
            "vllm_guided_decoding_regex=None,\n",
            "vllm_importance_sampling_cap=2.0,\n",
            "vllm_importance_sampling_correction=True,\n",
            "vllm_mode=server,\n",
            "vllm_model_impl=vllm,\n",
            "vllm_server_base_url=None,\n",
            "vllm_server_host=0.0.0.0,\n",
            "vllm_server_port=8000,\n",
            "vllm_server_timeout=240.0,\n",
            "vllm_tensor_parallel_size=1,\n",
            "wandb_log_unique_prompts=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]`generation_config` default values have been modified to match model-specific defaults: {'top_p': 0.95}. If this is not desired, please set these values explicitly.\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n",
            "\n",
            "  1%|          | 1/178 [00:15<44:32, 15.10s/it]\n",
            "  1%|          | 2/178 [00:29<43:11, 14.72s/it]\n",
            "                                               \n",
            "\n",
            "  1%|          | 2/178 [00:29<43:11, 14.72s/it]\n",
            "  2%|▏         | 3/178 [00:43<42:33, 14.59s/it]\n",
            "  2%|▏         | 4/178 [00:58<42:10, 14.54s/it]\n",
            "                                               \n",
            "\n",
            "  2%|▏         | 4/178 [00:58<42:10, 14.54s/it]\n",
            "  3%|▎         | 5/178 [01:13<41:58, 14.56s/it]\n",
            "  3%|▎         | 6/178 [01:27<41:35, 14.51s/it]\n",
            "                                               \n",
            "\n",
            "  3%|▎         | 6/178 [01:27<41:35, 14.51s/it]\n",
            "  4%|▍         | 7/178 [01:41<41:00, 14.39s/it]\n",
            "  4%|▍         | 8/178 [01:56<40:53, 14.43s/it]\n",
            "                                               \n",
            "\n",
            "  4%|▍         | 8/178 [01:56<40:53, 14.43s/it]\n",
            "  5%|▌         | 9/178 [02:03<34:10, 12.13s/it]\n",
            "  6%|▌         | 10/178 [02:17<36:07, 12.90s/it]\n",
            "                                                \n",
            "\n",
            "  6%|▌         | 10/178 [02:17<36:07, 12.90s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "\n",
            "  6%|▌         | 11/178 [02:27<33:22, 11.99s/it]\n",
            "  7%|▋         | 12/178 [02:42<35:15, 12.75s/it]\n",
            "                                                \n",
            "\n",
            "  7%|▋         | 12/178 [02:42<35:15, 12.75s/it]\n",
            "  7%|▋         | 13/178 [02:56<36:34, 13.30s/it]\n",
            "  8%|▊         | 14/178 [03:11<37:23, 13.68s/it]\n",
            "                                                \n",
            "\n",
            "  8%|▊         | 14/178 [03:11<37:23, 13.68s/it]\n",
            "  8%|▊         | 15/178 [03:25<37:53, 13.95s/it]\n",
            "  9%|▉         | 16/178 [03:40<38:05, 14.11s/it]\n",
            "                                                \n",
            "\n",
            "  9%|▉         | 16/178 [03:40<38:05, 14.11s/it]\n",
            " 10%|▉         | 17/178 [03:54<38:12, 14.24s/it]\n",
            " 10%|█         | 18/178 [04:09<38:09, 14.31s/it]\n",
            "                                                \n",
            "\n",
            " 10%|█         | 18/178 [04:09<38:09, 14.31s/it]\n",
            " 11%|█         | 19/178 [04:23<38:05, 14.37s/it]\n",
            " 11%|█         | 20/178 [04:38<38:02, 14.44s/it]\n",
            "                                                \n",
            "\n",
            " 11%|█         | 20/178 [04:38<38:02, 14.44s/it]\n",
            " 12%|█▏        | 21/178 [04:53<37:56, 14.50s/it]\n",
            " 12%|█▏        | 22/178 [05:07<37:42, 14.50s/it]\n",
            "                                                \n",
            "{'loss': 0.0209, 'grad_norm': 0.0, 'learning_rate': 2.7777777777777774e-08, 'num_tokens': 17158.0, 'completions/mean_length': 85.4375, 'completions/min_length': 27.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.5, 'completions/mean_terminated_length': 41.83333396911621, 'completions/min_terminated_length': 27.5, 'completions/max_terminated_length': 62.0, 'rewards/toxicity_reward_function/mean': 0.9954589903354645, 'rewards/toxicity_reward_function/std': 0.014305571428849362, 'reward': 0.9954589903354645, 'reward_std': 0.007229153285152279, 'frac_reward_zero_std': 0.0, 'entropy': 1.2126976251602173, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}\n",
            "{'loss': 0.0054, 'grad_norm': 0.0, 'learning_rate': 8.333333333333333e-08, 'num_tokens': 31500.0, 'completions/mean_length': 77.5625, 'completions/min_length': 30.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.3125, 'completions/mean_terminated_length': 54.97500038146973, 'completions/min_terminated_length': 30.0, 'completions/max_terminated_length': 100.0, 'rewards/toxicity_reward_function/mean': 0.9987154603004456, 'rewards/toxicity_reward_function/std': 0.0017360901838401332, 'reward': 0.9987154603004456, 'reward_std': 0.000967795989708975, 'frac_reward_zero_std': 0.0, 'entropy': 1.0226372927427292, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.02}\n",
            "{'loss': 0.0247, 'grad_norm': 0.0, 'learning_rate': 1.3888888888888888e-07, 'num_tokens': 48301.0, 'completions/mean_length': 94.40625, 'completions/min_length': 32.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.53125, 'completions/mean_terminated_length': 56.94643020629883, 'completions/min_terminated_length': 32.0, 'completions/max_terminated_length': 102.0, 'rewards/toxicity_reward_function/mean': 0.9989645481109619, 'rewards/toxicity_reward_function/std': 0.000371921545593068, 'reward': 0.9989645481109619, 'reward_std': 0.0003261407546233386, 'frac_reward_zero_std': 0.0, 'entropy': 1.169064611196518, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03}\n",
            "{'loss': 0.0315, 'grad_norm': 0.0, 'learning_rate': 1.9444444444444445e-07, 'num_tokens': 64967.0, 'completions/mean_length': 92.9375, 'completions/min_length': 43.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.5, 'completions/mean_terminated_length': 67.25, 'completions/min_terminated_length': 43.5, 'completions/max_terminated_length': 105.0, 'rewards/toxicity_reward_function/mean': 0.9989970028400421, 'rewards/toxicity_reward_function/std': 0.00038114287599455565, 'reward': 0.9989970028400421, 'reward_std': 0.00032792692945804447, 'frac_reward_zero_std': 0.0, 'entropy': 1.1852679252624512, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04}\n",
            "{'loss': -0.0123, 'grad_norm': 0.0, 'learning_rate': 2.5e-07, 'num_tokens': 78393.0, 'completions/mean_length': 63.0625, 'completions/min_length': 23.5, 'completions/max_length': 93.5, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 42.375, 'completions/min_terminated_length': 23.5, 'completions/max_terminated_length': 63.5, 'rewards/toxicity_reward_function/mean': 0.9964927732944489, 'rewards/toxicity_reward_function/std': 0.010741279751528054, 'reward': 0.9964927732944489, 'reward_std': 0.005418575674411841, 'frac_reward_zero_std': 0.0, 'entropy': 1.166344404220581, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06}\n",
            "{'loss': -0.0012, 'grad_norm': 0.0, 'learning_rate': 3.055555555555556e-07, 'num_tokens': 90974.0, 'completions/mean_length': 55.53125, 'completions/min_length': 26.0, 'completions/max_length': 106.5, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 44.96875, 'completions/min_terminated_length': 26.0, 'completions/max_terminated_length': 73.0, 'rewards/toxicity_reward_function/mean': 0.9991531670093536, 'rewards/toxicity_reward_function/std': 0.00019738284026971087, 'reward': 0.9991531670093536, 'reward_std': 0.00013280608618515544, 'frac_reward_zero_std': 0.0, 'entropy': 1.0777100175619125, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07}\n",
            "{'loss': -0.0149, 'grad_norm': 0.0, 'learning_rate': 3.6111111111111107e-07, 'num_tokens': 108483.0, 'completions/mean_length': 103.28125, 'completions/min_length': 30.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.625, 'completions/mean_terminated_length': 61.84285926818848, 'completions/min_terminated_length': 30.0, 'completions/max_terminated_length': 124.5, 'rewards/toxicity_reward_function/mean': 0.9991185963153839, 'rewards/toxicity_reward_function/std': 0.0003830685636785347, 'reward': 0.9991185963153839, 'reward_std': 0.00025466217266512103, 'frac_reward_zero_std': 0.0, 'entropy': 1.1498204171657562, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.08}\n",
            "{'loss': 0.0175, 'grad_norm': 0.0, 'learning_rate': 4.1666666666666667e-07, 'num_tokens': 122659.0, 'completions/mean_length': 71.625, 'completions/min_length': 21.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.3125, 'completions/mean_terminated_length': 46.491668701171875, 'completions/min_terminated_length': 21.5, 'completions/max_terminated_length': 87.5, 'rewards/toxicity_reward_function/mean': 0.998971700668335, 'rewards/toxicity_reward_function/std': 0.0005574215974775143, 'reward': 0.998971700668335, 'reward_std': 0.00038127101288409904, 'frac_reward_zero_std': 0.0, 'entropy': 1.1112747192382812, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.09}\n",
            "{'loss': -0.0303, 'grad_norm': 0.0, 'learning_rate': 4.722222222222222e-07, 'num_tokens': 140915.0, 'completions/mean_length': 96.0, 'completions/min_length': 29.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.53125, 'completions/mean_terminated_length': 59.81250190734863, 'completions/min_terminated_length': 29.0, 'completions/max_terminated_length': 114.0, 'rewards/toxicity_reward_function/mean': 0.9987640678882599, 'rewards/toxicity_reward_function/std': 0.0011666671198327094, 'reward': 0.9987640678882599, 'reward_std': 0.0008012795588001609, 'frac_reward_zero_std': 0.0, 'entropy': 1.188194751739502, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.1}\n",
            "{'loss': -0.0602, 'grad_norm': 0.0, 'learning_rate': 4.999518101205161e-07, 'num_tokens': 156216.0, 'completions/mean_length': 76.03125, 'completions/min_length': 31.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.3125, 'completions/mean_terminated_length': 53.25213813781738, 'completions/min_terminated_length': 31.0, 'completions/max_terminated_length': 71.0, 'rewards/toxicity_reward_function/mean': 0.9722204506397247, 'rewards/toxicity_reward_function/std': 0.09152303748851409, 'reward': 0.9722204506397247, 'reward_std': 0.0434981100843288, 'frac_reward_zero_std': 0.0, 'entropy': 1.025561511516571, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.11}\n",
            "{'loss': -0.0138, 'grad_norm': 0.0, 'learning_rate': 4.99566402546179e-07, 'num_tokens': 172752.0, 'completions/mean_length': 83.875, 'completions/min_length': 31.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.34375, 'completions/mean_terminated_length': 61.36111259460449, 'completions/min_terminated_length': 31.0, 'completions/max_terminated_length': 90.0, 'rewards/toxicity_reward_function/mean': 0.9991188049316406, 'rewards/toxicity_reward_function/std': 0.00031966499955160543, 'reward': 0.9991188049316406, 'reward_std': 0.00023019116633804515, 'frac_reward_zero_std': 0.0, 'entropy': 1.0763622522354126, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.12}\n",
            " 12%|█▏        | 22/178 [05:07<37:42, 14.50s/it]\n",
            " 13%|█▎        | 23/178 [05:22<37:30, 14.52s/it]\n",
            " 13%|█▎        | 24/178 [05:36<37:20, 14.55s/it]\n",
            "                                                \n",
            "\n",
            " 13%|█▎        | 24/178 [05:36<37:20, 14.55s/it]\n",
            " 14%|█▍        | 25/178 [05:51<37:03, 14.53s/it]\n",
            " 15%|█▍        | 26/178 [05:59<31:34, 12.46s/it]\n",
            "                                                \n",
            "\n",
            " 15%|█▍        | 26/178 [05:59<31:34, 12.46s/it]\n",
            " 15%|█▌        | 27/178 [06:13<32:57, 13.10s/it]\n",
            " 16%|█▌        | 28/178 [06:28<33:51, 13.54s/it]\n",
            "                                                \n",
            "\n",
            " 16%|█▌        | 28/178 [06:28<33:51, 13.54s/it]\n",
            " 16%|█▋        | 29/178 [06:42<34:26, 13.87s/it]\n",
            " 17%|█▋        | 30/178 [06:57<34:47, 14.11s/it]\n",
            "                                                \n",
            "\n",
            " 17%|█▋        | 30/178 [06:57<34:47, 14.11s/it]\n",
            " 17%|█▋        | 31/178 [07:11<34:52, 14.23s/it]\n",
            " 18%|█▊        | 32/178 [07:22<31:56, 13.13s/it]\n",
            "                                                \n",
            "\n",
            " 18%|█▊        | 32/178 [07:22<31:56, 13.13s/it]\n",
            " 19%|█▊        | 33/178 [07:37<32:51, 13.60s/it]\n",
            " 19%|█▉        | 34/178 [07:52<33:32, 13.97s/it]\n",
            "                                                \n",
            "\n",
            " 19%|█▉        | 34/178 [07:52<33:32, 13.97s/it]\n",
            " 20%|█▉        | 35/178 [08:03<31:35, 13.26s/it]\n",
            " 20%|██        | 36/178 [08:18<32:14, 13.62s/it]\n",
            "                                                \n",
            "\n",
            " 20%|██        | 36/178 [08:18<32:14, 13.62s/it]\n",
            " 21%|██        | 37/178 [08:27<29:05, 12.38s/it]\n",
            " 21%|██▏       | 38/178 [08:42<30:20, 13.01s/it]\n",
            "                                                \n",
            "\n",
            " 21%|██▏       | 38/178 [08:42<30:20, 13.01s/it]\n",
            " 22%|██▏       | 39/178 [08:56<31:13, 13.48s/it]\n",
            " 22%|██▏       | 40/178 [09:08<30:01, 13.05s/it]\n",
            "                                                \n",
            "\n",
            " 22%|██▏       | 40/178 [09:08<30:01, 13.05s/it]\n",
            " 23%|██▎       | 41/178 [09:23<30:48, 13.49s/it]\n",
            " 24%|██▎       | 42/178 [09:37<31:15, 13.79s/it]\n",
            "                                                \n",
            "\n",
            " 24%|██▎       | 42/178 [09:37<31:15, 13.79s/it]\n",
            " 24%|██▍       | 43/178 [09:43<25:46, 11.46s/it]\n",
            " 25%|██▍       | 44/178 [09:58<27:42, 12.41s/it]\n",
            "                                                \n",
            "{'loss': 0.0136, 'grad_norm': 0.0, 'learning_rate': 4.987961816680492e-07, 'num_tokens': 186626.0, 'completions/mean_length': 66.3125, 'completions/min_length': 22.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 45.75000190734863, 'completions/min_terminated_length': 22.5, 'completions/max_terminated_length': 67.0, 'rewards/toxicity_reward_function/mean': 0.9991356134414673, 'rewards/toxicity_reward_function/std': 0.00021504046162590384, 'reward': 0.9991356134414673, 'reward_std': 0.00010279238631483167, 'frac_reward_zero_std': 0.0, 'entropy': 1.1407442092895508, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.13}\n",
            "{'loss': -0.0112, 'grad_norm': 0.0, 'learning_rate': 4.976423351108942e-07, 'num_tokens': 200442.0, 'completions/mean_length': 63.75, 'completions/min_length': 26.0, 'completions/max_length': 96.0, 'completions/clipped_ratio': 0.15625, 'completions/mean_terminated_length': 53.3238639831543, 'completions/min_terminated_length': 26.0, 'completions/max_terminated_length': 95.0, 'rewards/toxicity_reward_function/mean': 0.9991450309753418, 'rewards/toxicity_reward_function/std': 0.0001547526007925626, 'reward': 0.9991450309753418, 'reward_std': 0.0001571958709973842, 'frac_reward_zero_std': 0.0, 'entropy': 1.0866546630859375, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.15}\n",
            "{'loss': -0.0146, 'grad_norm': 0.0, 'learning_rate': 4.961066420224729e-07, 'num_tokens': 217899.0, 'completions/mean_length': 75.03125, 'completions/min_length': 30.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.28125, 'completions/mean_terminated_length': 54.21590995788574, 'completions/min_terminated_length': 30.5, 'completions/max_terminated_length': 97.0, 'rewards/toxicity_reward_function/mean': 0.999198704957962, 'rewards/toxicity_reward_function/std': 0.00014590816499548964, 'reward': 0.999198704957962, 'reward_std': 9.351134940516204e-05, 'frac_reward_zero_std': 0.0, 'entropy': 1.0045607537031174, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.16}\n",
            "{'loss': -0.0214, 'grad_norm': 0.0, 'learning_rate': 4.941914703302181e-07, 'num_tokens': 232657.0, 'completions/mean_length': 86.3125, 'completions/min_length': 16.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.46875, 'completions/mean_terminated_length': 48.5, 'completions/min_terminated_length': 16.0, 'completions/max_terminated_length': 96.0, 'rewards/toxicity_reward_function/mean': 0.9925529062747955, 'rewards/toxicity_reward_function/std': 0.025513761618640274, 'reward': 0.9925529062747955, 'reward_std': 0.013249084557173774, 'frac_reward_zero_std': 0.0, 'entropy': 1.2250989079475403, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.17}\n",
            "{'loss': -0.0131, 'grad_norm': 0.0, 'learning_rate': 4.918997730900649e-07, 'num_tokens': 247236.0, 'completions/mean_length': 61.34375, 'completions/min_length': 19.0, 'completions/max_length': 109.5, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 52.98958396911621, 'completions/min_terminated_length': 19.0, 'completions/max_terminated_length': 92.0, 'rewards/toxicity_reward_function/mean': 0.999108225107193, 'rewards/toxicity_reward_function/std': 0.0002946155800600536, 'reward': 0.999108225107193, 'reward_std': 0.00020711670003947802, 'frac_reward_zero_std': 0.0, 'entropy': 1.1179394125938416, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.18}\n",
            "{'loss': 0.0675, 'grad_norm': 0.0, 'learning_rate': 4.892350839330522e-07, 'num_tokens': 261130.0, 'completions/mean_length': 66.6875, 'completions/min_length': 29.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 47.64444541931152, 'completions/min_terminated_length': 29.0, 'completions/max_terminated_length': 86.0, 'rewards/toxicity_reward_function/mean': 0.999198317527771, 'rewards/toxicity_reward_function/std': 0.00022322711447486654, 'reward': 0.999198317527771, 'reward_std': 0.0001555263952468522, 'frac_reward_zero_std': 0.0, 'entropy': 0.9919187724590302, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.19}\n",
            "{'loss': 0.0425, 'grad_norm': 0.0, 'learning_rate': 4.862015116167195e-07, 'num_tokens': 275138.0, 'completions/mean_length': 59.625, 'completions/min_length': 22.5, 'completions/max_length': 114.5, 'completions/clipped_ratio': 0.09375, 'completions/mean_terminated_length': 52.918270111083984, 'completions/min_terminated_length': 22.5, 'completions/max_terminated_length': 108.0, 'rewards/toxicity_reward_function/mean': 0.9991461336612701, 'rewards/toxicity_reward_function/std': 0.00026306946892873384, 'reward': 0.9991461336612701, 'reward_std': 0.00016861972108017653, 'frac_reward_zero_std': 0.0, 'entropy': 1.0713611543178558, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.2}\n",
            "{'loss': 0.0077, 'grad_norm': 0.0, 'learning_rate': 4.828037336897009e-07, 'num_tokens': 287075.0, 'completions/mean_length': 60.53125, 'completions/min_length': 24.5, 'completions/max_length': 105.5, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 51.75, 'completions/min_terminated_length': 24.5, 'completions/max_terminated_length': 100.0, 'rewards/toxicity_reward_function/mean': 0.9991866052150726, 'rewards/toxicity_reward_function/std': 0.00011728512617992237, 'reward': 0.9991866052150726, 'reward_std': 0.00010908877811743878, 'frac_reward_zero_std': 0.0, 'entropy': 0.9277630299329758, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.21}\n",
            "{'loss': 0.0086, 'grad_norm': 0.0, 'learning_rate': 4.79046989279284e-07, 'num_tokens': 300734.0, 'completions/mean_length': 55.96875, 'completions/min_length': 24.0, 'completions/max_length': 116.5, 'completions/clipped_ratio': 0.0625, 'completions/mean_terminated_length': 50.94643020629883, 'completions/min_terminated_length': 24.0, 'completions/max_terminated_length': 104.5, 'rewards/toxicity_reward_function/mean': 0.9987933337688446, 'rewards/toxicity_reward_function/std': 0.0009867108601611108, 'reward': 0.9987933337688446, 'reward_std': 0.0007175906648626551, 'frac_reward_zero_std': 0.0, 'entropy': 0.9838244169950485, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.22}\n",
            "{'loss': -0.0073, 'grad_norm': 0.0, 'learning_rate': 4.749370710130554e-07, 'num_tokens': 315842.0, 'completions/mean_length': 85.25, 'completions/min_length': 29.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.4375, 'completions/mean_terminated_length': 51.58749961853027, 'completions/min_terminated_length': 29.0, 'completions/max_terminated_length': 88.0, 'rewards/toxicity_reward_function/mean': 0.9968805909156799, 'rewards/toxicity_reward_function/std': 0.008647659575217403, 'reward': 0.9968805909156799, 'reward_std': 0.004390146918012761, 'frac_reward_zero_std': 0.0, 'entropy': 1.1484116166830063, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.24}\n",
            "{'loss': -0.0045, 'grad_norm': 0.0, 'learning_rate': 4.704803160870887e-07, 'num_tokens': 327723.0, 'completions/mean_length': 53.65625, 'completions/min_length': 27.0, 'completions/max_length': 88.0, 'completions/clipped_ratio': 0.09375, 'completions/mean_terminated_length': 47.028846740722656, 'completions/min_terminated_length': 27.0, 'completions/max_terminated_length': 85.5, 'rewards/toxicity_reward_function/mean': 0.9992001056671143, 'rewards/toxicity_reward_function/std': 0.00017187136108987033, 'reward': 0.9992001056671143, 'reward_std': 0.00015502471069339663, 'frac_reward_zero_std': 0.0, 'entropy': 0.9797430783510208, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.25}\n",
            " 25%|██▍       | 44/178 [09:58<27:42, 12.41s/it]\n",
            " 25%|██▌       | 45/178 [10:12<28:55, 13.05s/it]\n",
            " 26%|██▌       | 46/178 [10:27<29:42, 13.50s/it]\n",
            "                                                \n",
            "\n",
            " 26%|██▌       | 46/178 [10:27<29:42, 13.50s/it]\n",
            " 26%|██▋       | 47/178 [10:34<25:18, 11.59s/it]\n",
            " 27%|██▋       | 48/178 [10:49<27:05, 12.50s/it]\n",
            "                                                \n",
            "\n",
            " 27%|██▋       | 48/178 [10:49<27:05, 12.50s/it]\n",
            " 28%|██▊       | 49/178 [11:03<28:09, 13.10s/it]\n",
            " 28%|██▊       | 50/178 [11:18<28:57, 13.57s/it]\n",
            "                                                \n",
            "\n",
            " 28%|██▊       | 50/178 [11:18<28:57, 13.57s/it]\n",
            " 29%|██▊       | 51/178 [11:33<29:24, 13.89s/it]\n",
            " 29%|██▉       | 52/178 [11:47<29:41, 14.14s/it]\n",
            "                                                \n",
            "\n",
            " 29%|██▉       | 52/178 [11:47<29:41, 14.14s/it]\n",
            " 30%|██▉       | 53/178 [12:02<29:44, 14.28s/it]\n",
            " 30%|███       | 54/178 [12:16<29:41, 14.37s/it]\n",
            "                                                \n",
            "\n",
            " 30%|███       | 54/178 [12:16<29:41, 14.37s/it]\n",
            " 31%|███       | 55/178 [12:31<29:36, 14.44s/it]\n",
            " 31%|███▏      | 56/178 [12:46<29:31, 14.52s/it]\n",
            "                                                \n",
            "\n",
            " 31%|███▏      | 56/178 [12:46<29:31, 14.52s/it]\n",
            " 32%|███▏      | 57/178 [13:00<29:07, 14.44s/it]\n",
            " 33%|███▎      | 58/178 [13:15<29:01, 14.51s/it]\n",
            "                                                \n",
            "\n",
            " 33%|███▎      | 58/178 [13:15<29:01, 14.51s/it]\n",
            " 33%|███▎      | 59/178 [13:22<24:42, 12.46s/it]\n",
            " 34%|███▎      | 60/178 [13:37<25:44, 13.09s/it]\n",
            "                                                \n",
            "\n",
            " 34%|███▎      | 60/178 [13:37<25:44, 13.09s/it]\n",
            " 34%|███▍      | 61/178 [13:46<23:18, 11.96s/it]\n",
            " 35%|███▍      | 62/178 [13:55<21:17, 11.01s/it]\n",
            "                                                \n",
            "\n",
            " 35%|███▍      | 62/178 [13:55<21:17, 11.01s/it]\n",
            " 35%|███▌      | 63/178 [14:10<23:09, 12.08s/it]\n",
            " 36%|███▌      | 64/178 [14:16<19:39, 10.35s/it]\n",
            "                                                \n",
            "\n",
            " 36%|███▌      | 64/178 [14:16<19:39, 10.35s/it]\n",
            " 37%|███▋      | 65/178 [14:31<21:55, 11.64s/it]\n",
            " 37%|███▋      | 66/178 [14:45<23:26, 12.56s/it]\n",
            "                                                \n",
            "{'loss': 0.0244, 'grad_norm': 0.0, 'learning_rate': 4.6568359649444796e-07, 'num_tokens': 342819.0, 'completions/mean_length': 77.625, 'completions/min_length': 19.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.34375, 'completions/mean_terminated_length': 51.58333396911621, 'completions/min_terminated_length': 19.0, 'completions/max_terminated_length': 85.5, 'rewards/toxicity_reward_function/mean': 0.9987108409404755, 'rewards/toxicity_reward_function/std': 0.0011465899588074535, 'reward': 0.9987108409404755, 'reward_std': 0.0005103127914480865, 'frac_reward_zero_std': 0.0, 'entropy': 1.1427070498466492, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.26}\n",
            "{'loss': 0.0098, 'grad_norm': 0.0, 'learning_rate': 4.605543084290716e-07, 'num_tokens': 356185.0, 'completions/mean_length': 70.8125, 'completions/min_length': 31.5, 'completions/max_length': 94.5, 'completions/clipped_ratio': 0.3125, 'completions/mean_terminated_length': 48.3125, 'completions/min_terminated_length': 31.5, 'completions/max_terminated_length': 92.5, 'rewards/toxicity_reward_function/mean': 0.9990943372249603, 'rewards/toxicity_reward_function/std': 0.00019584519031923264, 'reward': 0.9990943372249603, 'reward_std': 0.00013279702034196816, 'frac_reward_zero_std': 0.0, 'entropy': 1.086101472377777, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.27}\n",
            "{'loss': 0.0082, 'grad_norm': 0.0, 'learning_rate': 4.5510036088137836e-07, 'num_tokens': 370102.0, 'completions/mean_length': 56.28125, 'completions/min_length': 21.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 46.01795196533203, 'completions/min_terminated_length': 21.5, 'completions/max_terminated_length': 80.5, 'rewards/toxicity_reward_function/mean': 0.9991715848445892, 'rewards/toxicity_reward_function/std': 0.00017931024194695055, 'reward': 0.9991715848445892, 'reward_std': 0.00010868151366594248, 'frac_reward_zero_std': 0.0, 'entropy': 1.0662040263414383, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.28}\n",
            "{'loss': -0.0117, 'grad_norm': 0.0, 'learning_rate': 4.4933016344317677e-07, 'num_tokens': 384302.0, 'completions/mean_length': 61.5, 'completions/min_length': 27.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.21875, 'completions/mean_terminated_length': 42.756412506103516, 'completions/min_terminated_length': 27.5, 'completions/max_terminated_length': 85.5, 'rewards/toxicity_reward_function/mean': 0.999110758304596, 'rewards/toxicity_reward_function/std': 0.00021526971977436915, 'reward': 0.999110758304596, 'reward_std': 0.00013062013022135943, 'frac_reward_zero_std': 0.0, 'entropy': 1.065167859196663, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.29}\n",
            "{'loss': 0.0102, 'grad_norm': 0.0, 'learning_rate': 4.432526133406842e-07, 'num_tokens': 398788.0, 'completions/mean_length': 66.0625, 'completions/min_length': 27.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.21875, 'completions/mean_terminated_length': 48.233333587646484, 'completions/min_terminated_length': 27.5, 'completions/max_terminated_length': 79.0, 'rewards/toxicity_reward_function/mean': 0.9991569221019745, 'rewards/toxicity_reward_function/std': 0.00034165016404585913, 'reward': 0.9991569221019745, 'reward_std': 0.00024230823328252882, 'frac_reward_zero_std': 0.0, 'entropy': 1.1451059430837631, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.3}\n",
            "{'loss': 0.0069, 'grad_norm': 0.0, 'learning_rate': 4.3687708171564917e-07, 'num_tokens': 412558.0, 'completions/mean_length': 64.8125, 'completions/min_length': 26.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.21875, 'completions/mean_terminated_length': 47.31089973449707, 'completions/min_terminated_length': 26.5, 'completions/max_terminated_length': 87.0, 'rewards/toxicity_reward_function/mean': 0.9990642666816711, 'rewards/toxicity_reward_function/std': 0.00032746975193731487, 'reward': 0.9990642666816711, 'reward_std': 0.00020135231170570478, 'frac_reward_zero_std': 0.0, 'entropy': 1.0926634967327118, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.31}\n",
            "{'loss': 0.0169, 'grad_norm': 0.0, 'learning_rate': 4.3021339917572967e-07, 'num_tokens': 431364.0, 'completions/mean_length': 96.4375, 'completions/min_length': 42.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.59375, 'completions/mean_terminated_length': 54.68181800842285, 'completions/min_terminated_length': 42.0, 'completions/max_terminated_length': 77.0, 'rewards/toxicity_reward_function/mean': 0.9991455972194672, 'rewards/toxicity_reward_function/std': 0.0001503405801486224, 'reward': 0.9991455972194672, 'reward_std': 0.00013615356147056445, 'frac_reward_zero_std': 0.0, 'entropy': 1.1835878789424896, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.33}\n",
            "{'loss': -0.0128, 'grad_norm': 0.0, 'learning_rate': 4.2327184063640895e-07, 'num_tokens': 445116.0, 'completions/mean_length': 51.75, 'completions/min_length': 25.0, 'completions/max_length': 95.5, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 40.25, 'completions/min_terminated_length': 25.0, 'completions/max_terminated_length': 63.0, 'rewards/toxicity_reward_function/mean': 0.9991800785064697, 'rewards/toxicity_reward_function/std': 0.00021609306713799015, 'reward': 0.9991800785064697, 'reward_std': 0.000154226079757791, 'frac_reward_zero_std': 0.0, 'entropy': 1.1569262593984604, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.34}\n",
            "{'loss': -0.0498, 'grad_norm': 0.0, 'learning_rate': 4.1606310947782043e-07, 'num_tokens': 455063.0, 'completions/mean_length': 43.84375, 'completions/min_length': 21.0, 'completions/max_length': 77.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 43.84375, 'completions/min_terminated_length': 21.0, 'completions/max_terminated_length': 77.0, 'rewards/toxicity_reward_function/mean': 0.9992285966873169, 'rewards/toxicity_reward_function/std': 0.00021392127382569015, 'reward': 0.9992285966873169, 'reward_std': 0.00016214947390835732, 'frac_reward_zero_std': 0.0, 'entropy': 1.052057296037674, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.35}\n",
            "{'loss': -0.0046, 'grad_norm': 0.0, 'learning_rate': 4.0859832104091136e-07, 'num_tokens': 465674.0, 'completions/mean_length': 52.59375, 'completions/min_length': 27.0, 'completions/max_length': 90.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 41.89583396911621, 'completions/min_terminated_length': 27.0, 'completions/max_terminated_length': 58.0, 'rewards/toxicity_reward_function/mean': 0.9992172718048096, 'rewards/toxicity_reward_function/std': 0.00016478097313665785, 'reward': 0.9992172718048096, 'reward_std': 0.00011783457375713624, 'frac_reward_zero_std': 0.0, 'entropy': 1.091310203075409, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.36}\n",
            "{'loss': -0.0361, 'grad_norm': 0.0, 'learning_rate': 4.0088898548839285e-07, 'num_tokens': 479097.0, 'completions/mean_length': 71.09375, 'completions/min_length': 26.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.28125, 'completions/mean_terminated_length': 49.05303192138672, 'completions/min_terminated_length': 26.0, 'completions/max_terminated_length': 99.5, 'rewards/toxicity_reward_function/mean': 0.9990552663803101, 'rewards/toxicity_reward_function/std': 0.0002523491421015933, 'reward': 0.9990552663803101, 'reward_std': 0.00021440139244077727, 'frac_reward_zero_std': 0.0, 'entropy': 1.3437901139259338, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.37}\n",
            " 37%|███▋      | 66/178 [14:45<23:26, 12.56s/it]\n",
            " 38%|███▊      | 67/178 [15:00<24:21, 13.17s/it]\n",
            " 38%|███▊      | 68/178 [15:15<24:58, 13.62s/it]\n",
            "                                                \n",
            "\n",
            " 38%|███▊      | 68/178 [15:15<24:58, 13.62s/it]\n",
            " 39%|███▉      | 69/178 [15:29<25:18, 13.93s/it]\n",
            " 39%|███▉      | 70/178 [15:44<25:39, 14.26s/it]\n",
            "                                                \n",
            "\n",
            " 39%|███▉      | 70/178 [15:44<25:39, 14.26s/it]\n",
            " 40%|███▉      | 71/178 [15:59<25:32, 14.32s/it]\n",
            " 40%|████      | 72/178 [16:13<25:26, 14.40s/it]\n",
            "                                                \n",
            "\n",
            " 40%|████      | 72/178 [16:13<25:26, 14.40s/it]\n",
            " 41%|████      | 73/178 [16:28<25:15, 14.44s/it]\n",
            " 42%|████▏     | 74/178 [16:37<22:10, 12.79s/it]\n",
            "                                                \n",
            "\n",
            " 42%|████▏     | 74/178 [16:37<22:10, 12.79s/it]\n",
            " 42%|████▏     | 75/178 [16:51<22:53, 13.33s/it]\n",
            " 43%|████▎     | 76/178 [17:06<23:16, 13.69s/it]\n",
            "                                                \n",
            "\n",
            " 43%|████▎     | 76/178 [17:06<23:16, 13.69s/it]\n",
            " 43%|████▎     | 77/178 [17:20<23:27, 13.94s/it]\n",
            " 44%|████▍     | 78/178 [17:35<23:34, 14.15s/it]\n",
            "                                                \n",
            "\n",
            " 44%|████▍     | 78/178 [17:35<23:34, 14.15s/it]\n",
            " 44%|████▍     | 79/178 [17:49<23:22, 14.17s/it]\n",
            " 45%|████▍     | 80/178 [18:04<23:20, 14.29s/it]\n",
            "                                                \n",
            "\n",
            " 45%|████▍     | 80/178 [18:04<23:20, 14.29s/it]\n",
            "{'loss': 0.0106, 'grad_norm': 0.0, 'learning_rate': 3.92946990056903e-07, 'num_tokens': 492299.0, 'completions/mean_length': 75.3125, 'completions/min_length': 25.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.375, 'completions/mean_terminated_length': 44.3125, 'completions/min_terminated_length': 25.0, 'completions/max_terminated_length': 73.5, 'rewards/toxicity_reward_function/mean': 0.9991243481636047, 'rewards/toxicity_reward_function/std': 0.00029542166157625616, 'reward': 0.9991243481636047, 'reward_std': 0.00021450375788845122, 'frac_reward_zero_std': 0.0, 'entropy': 1.3582297265529633, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.38}\n",
            "{'loss': 0.0112, 'grad_norm': 0.0, 'learning_rate': 3.847845807277501e-07, 'num_tokens': 507857.0, 'completions/mean_length': 80.8125, 'completions/min_length': 27.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.375, 'completions/mean_terminated_length': 52.454545974731445, 'completions/min_terminated_length': 27.5, 'completions/max_terminated_length': 88.0, 'rewards/toxicity_reward_function/mean': 0.9991808533668518, 'rewards/toxicity_reward_function/std': 0.00014930620818631724, 'reward': 0.9991808533668518, 'reward_std': 8.652033284306526e-05, 'frac_reward_zero_std': 0.0, 'entropy': 1.1962928175926208, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.39}\n",
            "{'loss': -0.0139, 'grad_norm': 0.0, 'learning_rate': 3.764143433444962e-07, 'num_tokens': 524994.0, 'completions/mean_length': 76.40625, 'completions/min_length': 37.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 60.70714569091797, 'completions/min_terminated_length': 37.0, 'completions/max_terminated_length': 111.5, 'rewards/toxicity_reward_function/mean': 0.9977321326732635, 'rewards/toxicity_reward_function/std': 0.0052011333900736645, 'reward': 0.9977321326732635, 'reward_std': 0.0027362623222870752, 'frac_reward_zero_std': 0.0, 'entropy': 1.099958449602127, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.4}\n",
            "{'loss': -0.0293, 'grad_norm': 0.0, 'learning_rate': 3.6784918420649944e-07, 'num_tokens': 537703.0, 'completions/mean_length': 51.40625, 'completions/min_length': 27.5, 'completions/max_length': 101.5, 'completions/clipped_ratio': 0.03125, 'completions/mean_terminated_length': 48.970834732055664, 'completions/min_terminated_length': 27.5, 'completions/max_terminated_length': 87.5, 'rewards/toxicity_reward_function/mean': 0.9991391897201538, 'rewards/toxicity_reward_function/std': 0.00020322512136772275, 'reward': 0.9991391897201538, 'reward_std': 0.00014548782201018184, 'frac_reward_zero_std': 0.0, 'entropy': 1.0181753039360046, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.42}\n",
            "{'loss': 0.0138, 'grad_norm': 0.0, 'learning_rate': 3.5910231016833546e-07, 'num_tokens': 554110.0, 'completions/mean_length': 86.46875, 'completions/min_length': 29.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.40625, 'completions/mean_terminated_length': 56.31547737121582, 'completions/min_terminated_length': 29.5, 'completions/max_terminated_length': 97.5, 'rewards/toxicity_reward_function/mean': 0.9991192817687988, 'rewards/toxicity_reward_function/std': 0.00022929706028662622, 'reward': 0.9991192817687988, 'reward_std': 0.00016130058793351054, 'frac_reward_zero_std': 0.0, 'entropy': 1.0856008976697922, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.43}\n",
            "{'loss': -0.011, 'grad_norm': 0.0, 'learning_rate': 3.5018720827578516e-07, 'num_tokens': 567778.0, 'completions/mean_length': 66.375, 'completions/min_length': 32.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.15625, 'completions/mean_terminated_length': 54.87362861633301, 'completions/min_terminated_length': 32.5, 'completions/max_terminated_length': 126.5, 'rewards/toxicity_reward_function/mean': 0.9990846812725067, 'rewards/toxicity_reward_function/std': 0.00022769115457776934, 'reward': 0.9990846812725067, 'reward_std': 0.0001557616633363068, 'frac_reward_zero_std': 0.0, 'entropy': 1.211573749780655, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.44}\n",
            "{'loss': 0.0023, 'grad_norm': 0.0, 'learning_rate': 3.411176249697875e-07, 'num_tokens': 585564.0, 'completions/mean_length': 88.5625, 'completions/min_length': 47.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.4375, 'completions/mean_terminated_length': 65.53333473205566, 'completions/min_terminated_length': 47.5, 'completions/max_terminated_length': 96.5, 'rewards/toxicity_reward_function/mean': 0.9991163909435272, 'rewards/toxicity_reward_function/std': 0.00022822142636869103, 'reward': 0.9991163909435272, 'reward_std': 0.0001347163852187805, 'frac_reward_zero_std': 0.0, 'entropy': 1.0895598381757736, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.45}\n",
            "\n",
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  3%|▎         | 2/76 [00:06<03:47,  3.08s/it]\u001b[A\n",
            "\n",
            "  4%|▍         | 3/76 [00:18<08:24,  6.92s/it]\u001b[A\n",
            "\n",
            "  5%|▌         | 4/76 [00:30<10:41,  8.91s/it]\u001b[A\n",
            "\n",
            "  7%|▋         | 5/76 [00:37<09:39,  8.16s/it]\u001b[A\n",
            "\n",
            "  8%|▊         | 6/76 [00:49<11:05,  9.51s/it]\u001b[A\n",
            "\n",
            "  9%|▉         | 7/76 [01:02<12:06, 10.52s/it]\u001b[A\n",
            "\n",
            " 11%|█         | 8/76 [01:14<12:40, 11.19s/it]\u001b[A\n",
            "\n",
            " 12%|█▏        | 9/76 [01:27<12:59, 11.64s/it]\u001b[A\n",
            "\n",
            " 13%|█▎        | 10/76 [01:39<13:00, 11.82s/it]\u001b[A\n",
            "\n",
            " 14%|█▍        | 11/76 [01:52<13:07, 12.11s/it]\u001b[A\n",
            "\n",
            " 16%|█▌        | 12/76 [02:05<13:09, 12.34s/it]\u001b[A\n",
            "\n",
            " 17%|█▋        | 13/76 [02:17<12:56, 12.33s/it]\u001b[A\n",
            "\n",
            " 18%|█▊        | 14/76 [02:30<12:45, 12.34s/it]\u001b[A\n",
            "\n",
            " 20%|█▉        | 15/76 [02:42<12:41, 12.48s/it]\u001b[A\n",
            "\n",
            " 21%|██        | 16/76 [02:55<12:32, 12.54s/it]\u001b[A\n",
            "\n",
            " 22%|██▏       | 17/76 [03:07<12:15, 12.46s/it]\u001b[A\n",
            "\n",
            " 24%|██▎       | 18/76 [03:14<10:20, 10.71s/it]\u001b[A\n",
            "\n",
            " 25%|██▌       | 19/76 [03:27<10:43, 11.29s/it]\u001b[A\n",
            "\n",
            " 26%|██▋       | 20/76 [03:39<10:55, 11.71s/it]\u001b[A\n",
            "\n",
            " 28%|██▊       | 21/76 [03:52<10:59, 12.00s/it]\u001b[A\n",
            "\n",
            " 29%|██▉       | 22/76 [04:05<10:59, 12.22s/it]\u001b[A\n",
            "\n",
            " 30%|███       | 23/76 [04:14<09:54, 11.21s/it]\u001b[A\n",
            "\n",
            " 32%|███▏      | 24/76 [04:26<10:00, 11.54s/it]\u001b[A\n",
            "\n",
            " 33%|███▎      | 25/76 [04:33<08:46, 10.33s/it]\u001b[A\n",
            "\n",
            " 34%|███▍      | 26/76 [04:46<09:07, 10.95s/it]\u001b[A\n",
            "\n",
            " 36%|███▌      | 27/76 [04:59<09:22, 11.49s/it]\u001b[A\n",
            "\n",
            " 37%|███▋      | 28/76 [05:11<09:23, 11.75s/it]\u001b[A\n",
            "\n",
            " 38%|███▊      | 29/76 [05:23<09:20, 11.92s/it]\u001b[A\n",
            "\n",
            " 39%|███▉      | 30/76 [05:36<09:18, 12.14s/it]\u001b[A\n",
            "\n",
            " 41%|████      | 31/76 [05:49<09:19, 12.44s/it]\u001b[A\n",
            "\n",
            " 42%|████▏     | 32/76 [06:01<09:03, 12.35s/it]\u001b[A\n",
            "\n",
            " 43%|████▎     | 33/76 [06:06<07:18, 10.20s/it]\u001b[A\n",
            "\n",
            " 45%|████▍     | 34/76 [06:19<07:33, 10.79s/it]\u001b[A\n",
            "\n",
            " 46%|████▌     | 35/76 [06:31<07:38, 11.19s/it]\u001b[A\n",
            "\n",
            " 47%|████▋     | 36/76 [06:43<07:45, 11.63s/it]\u001b[A\n",
            "\n",
            " 49%|████▊     | 37/76 [06:56<07:44, 11.91s/it]\u001b[A\n",
            "\n",
            " 50%|█████     | 38/76 [07:09<07:41, 12.15s/it]\u001b[A\n",
            "\n",
            " 51%|█████▏    | 39/76 [07:21<07:35, 12.30s/it]\u001b[A\n",
            "\n",
            " 53%|█████▎    | 40/76 [07:34<07:26, 12.39s/it]\u001b[A\n",
            "\n",
            " 54%|█████▍    | 41/76 [07:47<07:17, 12.49s/it]\u001b[A\n",
            "\n",
            " 55%|█████▌    | 42/76 [07:59<07:06, 12.55s/it]\u001b[A\n",
            "\n",
            " 57%|█████▋    | 43/76 [08:12<06:55, 12.58s/it]\u001b[A\n",
            "\n",
            " 58%|█████▊    | 44/76 [08:24<06:39, 12.49s/it]\u001b[A\n",
            "\n",
            " 59%|█████▉    | 45/76 [08:37<06:29, 12.55s/it]\u001b[A\n",
            "\n",
            " 61%|██████    | 46/76 [08:44<05:29, 10.99s/it]\u001b[A\n",
            "\n",
            " 62%|██████▏   | 47/76 [08:49<04:27,  9.21s/it]\u001b[A\n",
            "\n",
            " 63%|██████▎   | 48/76 [09:02<04:47, 10.28s/it]\u001b[A\n",
            "\n",
            " 64%|██████▍   | 49/76 [09:14<04:53, 10.88s/it]\u001b[A\n",
            "\n",
            " 66%|██████▌   | 50/76 [09:27<04:57, 11.44s/it]\u001b[A\n",
            "\n",
            " 67%|██████▋   | 51/76 [09:40<04:55, 11.81s/it]\u001b[A\n",
            "\n",
            " 68%|██████▊   | 52/76 [09:52<04:47, 11.99s/it]\u001b[A\n",
            "\n",
            " 70%|██████▉   | 53/76 [10:05<04:38, 12.10s/it]\u001b[A\n",
            "\n",
            " 71%|███████   | 54/76 [10:17<04:31, 12.33s/it]\u001b[A\n",
            "\n",
            " 72%|███████▏  | 55/76 [10:30<04:19, 12.34s/it]\u001b[A\n",
            "\n",
            " 74%|███████▎  | 56/76 [10:42<04:09, 12.45s/it]\u001b[A\n",
            "\n",
            " 75%|███████▌  | 57/76 [10:55<03:55, 12.40s/it]\u001b[A\n",
            "\n",
            " 76%|███████▋  | 58/76 [11:07<03:44, 12.49s/it]\u001b[A\n",
            "\n",
            " 78%|███████▊  | 59/76 [11:16<03:12, 11.33s/it]\u001b[A\n",
            "\n",
            " 79%|███████▉  | 60/76 [11:29<03:08, 11.76s/it]\u001b[A\n",
            "\n",
            " 80%|████████  | 61/76 [11:42<03:00, 12.03s/it]\u001b[A\n",
            "\n",
            " 82%|████████▏ | 62/76 [11:54<02:49, 12.10s/it]\u001b[A\n",
            "\n",
            " 83%|████████▎ | 63/76 [12:07<02:39, 12.29s/it]\u001b[A\n",
            "\n",
            " 84%|████████▍ | 64/76 [12:19<02:29, 12.43s/it]\u001b[A\n",
            "\n",
            " 86%|████████▌ | 65/76 [12:28<02:02, 11.18s/it]\u001b[A\n",
            "\n",
            " 87%|████████▋ | 66/76 [12:40<01:55, 11.52s/it]\u001b[A\n",
            "\n",
            " 88%|████████▊ | 67/76 [12:52<01:46, 11.85s/it]\u001b[A\n",
            "\n",
            " 89%|████████▉ | 68/76 [13:05<01:35, 12.00s/it]\u001b[A\n",
            "\n",
            " 91%|█████████ | 69/76 [13:17<01:24, 12.11s/it]\u001b[A\n",
            "\n",
            " 92%|█████████▏| 70/76 [13:30<01:13, 12.20s/it]\u001b[A\n",
            "\n",
            " 93%|█████████▎| 71/76 [13:35<00:51, 10.24s/it]\u001b[A\n",
            "\n",
            " 95%|█████████▍| 72/76 [13:47<00:43, 10.84s/it]\u001b[A\n",
            "\n",
            " 96%|█████████▌| 73/76 [14:00<00:34, 11.42s/it]\u001b[A\n",
            "\n",
            " 97%|█████████▋| 74/76 [14:13<00:23, 11.81s/it]\u001b[A\n",
            "\n",
            " 99%|█████████▊| 75/76 [14:26<00:12, 12.03s/it]\u001b[A\n",
            "\n",
            "100%|██████████| 76/76 [14:38<00:00, 12.18s/it]\u001b[A\n",
            "                                                \n",
            "\n",
            "                                               \n",
            "\u001b[A\n",
            " 45%|████▍     | 80/178 [32:55<23:20, 14.29s/it]\n",
            "\n",
            "100%|██████████| 76/76 [14:38<00:00, 12.18s/it]\u001b[A\n",
            "\n",
            "                                               \u001b[A/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n",
            "\n",
            " 46%|████▌     | 81/178 [33:10<7:35:43, 281.89s/it]\n",
            " 46%|████▌     | 82/178 [33:25<5:22:45, 201.72s/it]\n",
            "                                                   \n",
            "\n",
            " 46%|████▌     | 82/178 [33:25<5:22:45, 201.72s/it]\n",
            " 47%|████▋     | 83/178 [33:39<3:50:33, 145.62s/it]\n",
            " 47%|████▋     | 84/178 [33:54<2:46:36, 106.34s/it]\n",
            "                                                   \n",
            "\n",
            " 47%|████▋     | 84/178 [33:54<2:46:36, 106.34s/it]\n",
            " 48%|████▊     | 85/178 [34:09<2:02:11, 78.83s/it] \n",
            " 48%|████▊     | 86/178 [34:23<1:31:21, 59.58s/it]\n",
            "                                                  \n",
            "\n",
            " 48%|████▊     | 86/178 [34:23<1:31:21, 59.58s/it]\n",
            " 49%|████▉     | 87/178 [34:38<1:09:57, 46.13s/it]\n",
            " 49%|████▉     | 88/178 [34:52<54:50, 36.57s/it]  \n",
            "                                                \n",
            "\n",
            " 49%|████▉     | 88/178 [34:52<54:50, 36.57s/it]\n",
            " 50%|█████     | 89/178 [35:07<44:27, 29.97s/it]\n",
            " 51%|█████     | 90/178 [35:22<37:13, 25.38s/it]\n",
            "                                                \n",
            "\n",
            " 51%|█████     | 90/178 [35:22<37:13, 25.38s/it]\n",
            " 51%|█████     | 91/178 [35:36<32:09, 22.18s/it]\n",
            " 52%|█████▏    | 92/178 [35:51<28:36, 19.95s/it]\n",
            "                                                \n",
            "\n",
            " 52%|█████▏    | 92/178 [35:51<28:36, 19.95s/it]\n",
            " 52%|█████▏    | 93/178 [36:06<26:00, 18.36s/it]\n",
            " 53%|█████▎    | 94/178 [36:21<24:10, 17.26s/it]\n",
            "                                                \n",
            "\n",
            " 53%|█████▎    | 94/178 [36:21<24:10, 17.26s/it]\n",
            " 53%|█████▎    | 95/178 [36:35<22:46, 16.47s/it]\n",
            " 54%|█████▍    | 96/178 [36:50<21:47, 15.94s/it]\n",
            "                                                \n",
            "\n",
            " 54%|█████▍    | 96/178 [36:50<21:47, 15.94s/it]\n",
            " 54%|█████▍    | 97/178 [37:05<21:02, 15.58s/it]\n",
            " 55%|█████▌    | 98/178 [37:19<20:22, 15.28s/it]\n",
            "                                                \n",
            "\n",
            " 55%|█████▌    | 98/178 [37:19<20:22, 15.28s/it]\n",
            " 56%|█████▌    | 99/178 [37:33<19:44, 14.99s/it]\n",
            " 56%|█████▌    | 100/178 [37:48<19:25, 14.94s/it]\n",
            "                                                 \n",
            "{'eval_loss': 0.0021826568990945816, 'eval_runtime': 890.8394, 'eval_samples_per_second': 0.171, 'eval_steps_per_second': 0.021, 'eval_num_tokens': 585564.0, 'eval_completions/mean_length': 91.03782894736842, 'eval_completions/min_length': 55.39473684210526, 'eval_completions/max_length': 119.47368421052632, 'eval_completions/clipped_ratio': 0.5148026315789473, 'eval_completions/mean_terminated_length': 49.66387884240402, 'eval_completions/min_terminated_length': 36.86842105263158, 'eval_completions/max_terminated_length': 67.78947368421052, 'eval_rewards/toxicity_reward_function/mean': 0.9955145528441981, 'eval_rewards/toxicity_reward_function/std': 0.01033419762346679, 'eval_reward': 0.9955145528441981, 'eval_reward_std': 0.007324639491726933, 'eval_frac_reward_zero_std': 0.0, 'eval_entropy': 1.19448395622404, 'eval_clip_ratio/low_mean': 0.0, 'eval_clip_ratio/low_min': 0.0, 'eval_clip_ratio/high_mean': 0.0, 'eval_clip_ratio/high_max': 0.0, 'eval_clip_ratio/region_mean': 0.0, 'epoch': 0.45}\n",
            "{'loss': -0.0036, 'grad_norm': 0.0, 'learning_rate': 3.3190754489042337e-07, 'num_tokens': 600380.0, 'completions/mean_length': 74.625, 'completions/min_length': 29.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.34375, 'completions/mean_terminated_length': 47.16666793823242, 'completions/min_terminated_length': 29.5, 'completions/max_terminated_length': 81.0, 'rewards/toxicity_reward_function/mean': 0.9991522133350372, 'rewards/toxicity_reward_function/std': 0.0003026422709808685, 'reward': 0.9991522133350372, 'reward_std': 0.00017293591736233793, 'frac_reward_zero_std': 0.0, 'entropy': 1.19612355530262, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.46}\n",
            "{'loss': -0.0101, 'grad_norm': 0.0, 'learning_rate': 3.2257116931361555e-07, 'num_tokens': 616793.0, 'completions/mean_length': 71.53125, 'completions/min_length': 25.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.28125, 'completions/mean_terminated_length': 47.670637130737305, 'completions/min_terminated_length': 25.5, 'completions/max_terminated_length': 88.0, 'rewards/toxicity_reward_function/mean': 0.9990511536598206, 'rewards/toxicity_reward_function/std': 0.0003129620017716661, 'reward': 0.9990511536598206, 'reward_std': 0.00020262390535208397, 'frac_reward_zero_std': 0.0, 'entropy': 1.043623685836792, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.47}\n",
            "{'loss': -0.0026, 'grad_norm': 0.0, 'learning_rate': 3.1312289425378944e-07, 'num_tokens': 634054.0, 'completions/mean_length': 94.03125, 'completions/min_length': 28.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.5625, 'completions/mean_terminated_length': 51.85416793823242, 'completions/min_terminated_length': 28.0, 'completions/max_terminated_length': 91.5, 'rewards/toxicity_reward_function/mean': 0.9976917505264282, 'rewards/toxicity_reward_function/std': 0.005458329018438235, 'reward': 0.9976917505264282, 'reward_std': 0.0027641626656986773, 'frac_reward_zero_std': 0.0, 'entropy': 1.3007134199142456, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.48}\n",
            "{'loss': 0.0232, 'grad_norm': 0.0, 'learning_rate': 3.0357728826626267e-07, 'num_tokens': 650748.0, 'completions/mean_length': 89.0625, 'completions/min_length': 39.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.4375, 'completions/mean_terminated_length': 66.75000381469727, 'completions/min_terminated_length': 39.5, 'completions/max_terminated_length': 89.5, 'rewards/toxicity_reward_function/mean': 0.9989436268806458, 'rewards/toxicity_reward_function/std': 0.00026996207452612, 'reward': 0.9989436268806458, 'reward_std': 0.00017647257482167333, 'frac_reward_zero_std': 0.0, 'entropy': 1.211598426103592, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.49}\n",
            "{'loss': 0.0249, 'grad_norm': 0.0, 'learning_rate': 2.9394906998358865e-07, 'num_tokens': 663858.0, 'completions/mean_length': 62.0625, 'completions/min_length': 23.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.15625, 'completions/mean_terminated_length': 49.84615707397461, 'completions/min_terminated_length': 23.5, 'completions/max_terminated_length': 94.5, 'rewards/toxicity_reward_function/mean': 0.9991614520549774, 'rewards/toxicity_reward_function/std': 0.000179201721039135, 'reward': 0.9991614520549774, 'reward_std': 0.00015004585293354467, 'frac_reward_zero_std': 0.0, 'entropy': 1.093221738934517, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.51}\n",
            "{'loss': -0.0009, 'grad_norm': 0.0, 'learning_rate': 2.84253085420492e-07, 'num_tokens': 679892.0, 'completions/mean_length': 79.4375, 'completions/min_length': 26.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.375, 'completions/mean_terminated_length': 53.3125, 'completions/min_terminated_length': 26.0, 'completions/max_terminated_length': 79.0, 'rewards/toxicity_reward_function/mean': 0.9990839958190918, 'rewards/toxicity_reward_function/std': 0.0007673122090636753, 'reward': 0.9990839958190918, 'reward_std': 0.00046224082325352356, 'frac_reward_zero_std': 0.0, 'entropy': 1.1630556881427765, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.52}\n",
            "{'loss': -0.0234, 'grad_norm': 0.0, 'learning_rate': 2.745042850823902e-07, 'num_tokens': 694965.0, 'completions/mean_length': 71.90625, 'completions/min_length': 34.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.28125, 'completions/mean_terminated_length': 49.179168701171875, 'completions/min_terminated_length': 34.5, 'completions/max_terminated_length': 71.5, 'rewards/toxicity_reward_function/mean': 0.9985710680484772, 'rewards/toxicity_reward_function/std': 0.0023853275342844427, 'reward': 0.9985710680484772, 'reward_std': 0.0012482183374231681, 'frac_reward_zero_std': 0.0, 'entropy': 1.1277874261140823, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.53}\n",
            "{'loss': 0.0195, 'grad_norm': 0.0, 'learning_rate': 2.647177009127972e-07, 'num_tokens': 709067.0, 'completions/mean_length': 76.9375, 'completions/min_length': 28.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.3125, 'completions/mean_terminated_length': 53.80341911315918, 'completions/min_terminated_length': 28.5, 'completions/max_terminated_length': 106.0, 'rewards/toxicity_reward_function/mean': 0.9987401962280273, 'rewards/toxicity_reward_function/std': 0.0016444350258097984, 'reward': 0.9987401962280273, 'reward_std': 0.0009389118276885711, 'frac_reward_zero_std': 0.0, 'entropy': 1.1313989162445068, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.54}\n",
            "{'loss': -0.0117, 'grad_norm': 0.0, 'learning_rate': 2.5490842311515704e-07, 'num_tokens': 726782.0, 'completions/mean_length': 100.09375, 'completions/min_length': 26.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.625, 'completions/mean_terminated_length': 51.18571662902832, 'completions/min_terminated_length': 26.0, 'completions/max_terminated_length': 89.0, 'rewards/toxicity_reward_function/mean': 0.9989141821861267, 'rewards/toxicity_reward_function/std': 0.0008195823611458763, 'reward': 0.9989141821861267, 'reward_std': 0.000495497472002171, 'frac_reward_zero_std': 0.0, 'entropy': 1.3588902056217194, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.55}\n",
            "{'loss': 0.0431, 'grad_norm': 0.0, 'learning_rate': 2.4509157688484294e-07, 'num_tokens': 744598.0, 'completions/mean_length': 101.5, 'completions/min_length': 47.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.625, 'completions/mean_terminated_length': 62.33333396911621, 'completions/min_terminated_length': 47.5, 'completions/max_terminated_length': 80.5, 'rewards/toxicity_reward_function/mean': 0.9987461864948273, 'rewards/toxicity_reward_function/std': 0.001214512187289074, 'reward': 0.9987461864948273, 'reward_std': 0.0007763210887787864, 'frac_reward_zero_std': 0.0, 'entropy': 1.2493955492973328, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.56}\n",
            " 56%|█████▌    | 100/178 [37:48<19:25, 14.94s/it]\n",
            " 57%|█████▋    | 101/178 [38:03<19:06, 14.89s/it]\n",
            " 57%|█████▋    | 102/178 [38:18<18:46, 14.82s/it]\n",
            "                                                 \n",
            "\n",
            " 57%|█████▋    | 102/178 [38:18<18:46, 14.82s/it]\n",
            " 58%|█████▊    | 103/178 [38:32<18:29, 14.79s/it]\n",
            " 58%|█████▊    | 104/178 [38:47<18:13, 14.77s/it]\n",
            "                                                 \n",
            "\n",
            " 58%|█████▊    | 104/178 [38:47<18:13, 14.77s/it]\n",
            " 59%|█████▉    | 105/178 [39:02<17:53, 14.70s/it]\n",
            " 60%|█████▉    | 106/178 [39:16<17:37, 14.68s/it]\n",
            "                                                 \n",
            "\n",
            " 60%|█████▉    | 106/178 [39:16<17:37, 14.68s/it]\n",
            " 60%|██████    | 107/178 [39:25<15:03, 12.72s/it]\n",
            " 61%|██████    | 108/178 [39:32<13:05, 11.23s/it]\n",
            "                                                 \n",
            "\n",
            " 61%|██████    | 108/178 [39:32<13:05, 11.23s/it]\n",
            " 61%|██████    | 109/178 [39:47<14:07, 12.28s/it]\n",
            " 62%|██████▏   | 110/178 [40:02<14:42, 12.98s/it]\n",
            "                                                 \n",
            "\n",
            " 62%|██████▏   | 110/178 [40:02<14:42, 12.98s/it]\n",
            " 62%|██████▏   | 111/178 [40:16<15:02, 13.47s/it]\n",
            " 63%|██████▎   | 112/178 [40:31<15:20, 13.95s/it]\n",
            "                                                 \n",
            "\n",
            " 63%|██████▎   | 112/178 [40:31<15:20, 13.95s/it]\n",
            " 63%|██████▎   | 113/178 [40:46<15:18, 14.13s/it]\n",
            " 64%|██████▍   | 114/178 [41:00<15:11, 14.24s/it]\n",
            "                                                 \n",
            "\n",
            " 64%|██████▍   | 114/178 [41:00<15:11, 14.24s/it]\n",
            " 65%|██████▍   | 115/178 [41:15<15:03, 14.34s/it]\n",
            " 65%|██████▌   | 116/178 [41:30<14:54, 14.42s/it]\n",
            "                                                 \n",
            "\n",
            " 65%|██████▌   | 116/178 [41:30<14:54, 14.42s/it]\n",
            " 66%|██████▌   | 117/178 [41:44<14:40, 14.44s/it]\n",
            " 66%|██████▋   | 118/178 [41:59<14:30, 14.50s/it]\n",
            "                                                 \n",
            "\n",
            " 66%|██████▋   | 118/178 [41:59<14:30, 14.50s/it]\n",
            " 67%|██████▋   | 119/178 [42:13<14:18, 14.56s/it]\n",
            " 67%|██████▋   | 120/178 [42:28<14:08, 14.62s/it]\n",
            "                                                 \n",
            "\n",
            " 67%|██████▋   | 120/178 [42:28<14:08, 14.62s/it]\n",
            " 68%|██████▊   | 121/178 [42:36<12:04, 12.72s/it]\n",
            " 69%|██████▊   | 122/178 [42:51<12:25, 13.31s/it]\n",
            "                                                 \n",
            "{'loss': 0.0229, 'grad_norm': 0.0, 'learning_rate': 2.352822990872027e-07, 'num_tokens': 758734.0, 'completions/mean_length': 63.375, 'completions/min_length': 22.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.21875, 'completions/mean_terminated_length': 45.47756576538086, 'completions/min_terminated_length': 22.5, 'completions/max_terminated_length': 101.0, 'rewards/toxicity_reward_function/mean': 0.9823523461818695, 'rewards/toxicity_reward_function/std': 0.06699515585205518, 'reward': 0.9823523461818695, 'reward_std': 0.0335077045019716, 'frac_reward_zero_std': 0.0, 'entropy': 0.9952027499675751, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.57}\n",
            "{'loss': 0.0167, 'grad_norm': 0.0, 'learning_rate': 2.2549571491760981e-07, 'num_tokens': 776809.0, 'completions/mean_length': 95.46875, 'completions/min_length': 41.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.53125, 'completions/mean_terminated_length': 59.45000076293945, 'completions/min_terminated_length': 41.5, 'completions/max_terminated_length': 100.5, 'rewards/toxicity_reward_function/mean': 0.998829573392868, 'rewards/toxicity_reward_function/std': 0.0008406524721067399, 'reward': 0.998829573392868, 'reward_std': 0.0004433763097040355, 'frac_reward_zero_std': 0.0, 'entropy': 1.1685106754302979, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.58}\n",
            "{'loss': 0.0333, 'grad_norm': 0.0, 'learning_rate': 2.1574691457950803e-07, 'num_tokens': 790295.0, 'completions/mean_length': 67.1875, 'completions/min_length': 25.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.21875, 'completions/mean_terminated_length': 50.45454788208008, 'completions/min_terminated_length': 25.0, 'completions/max_terminated_length': 105.5, 'rewards/toxicity_reward_function/mean': 0.999151349067688, 'rewards/toxicity_reward_function/std': 0.00022467015514848754, 'reward': 0.999151349067688, 'reward_std': 0.00015258136409102008, 'frac_reward_zero_std': 0.0, 'entropy': 1.1893786489963531, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.6}\n",
            "{'loss': -0.0232, 'grad_norm': 0.0, 'learning_rate': 2.0605093001641135e-07, 'num_tokens': 800236.0, 'completions/mean_length': 43.15625, 'completions/min_length': 25.0, 'completions/max_length': 65.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 43.15625, 'completions/min_terminated_length': 25.0, 'completions/max_terminated_length': 65.0, 'rewards/toxicity_reward_function/mean': 0.9991508424282074, 'rewards/toxicity_reward_function/std': 0.00026015090770670213, 'reward': 0.9991508424282074, 'reward_std': 0.0001805728898034431, 'frac_reward_zero_std': 0.0, 'entropy': 1.0300772041082382, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.61}\n",
            "{'loss': -0.0228, 'grad_norm': 0.0, 'learning_rate': 1.9642271173373734e-07, 'num_tokens': 814574.0, 'completions/mean_length': 65.1875, 'completions/min_length': 27.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 44.25, 'completions/min_terminated_length': 27.5, 'completions/max_terminated_length': 82.0, 'rewards/toxicity_reward_function/mean': 0.9804283380508423, 'rewards/toxicity_reward_function/std': 0.04922728150268085, 'reward': 0.9804283380508423, 'reward_std': 0.02034753556654323, 'frac_reward_zero_std': 0.0, 'entropy': 1.0864529609680176, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.62}\n",
            "{'loss': 0.0075, 'grad_norm': 0.0, 'learning_rate': 1.8687710574621048e-07, 'num_tokens': 828939.0, 'completions/mean_length': 61.28125, 'completions/min_length': 22.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 39.04166793823242, 'completions/min_terminated_length': 22.0, 'completions/max_terminated_length': 62.5, 'rewards/toxicity_reward_function/mean': 0.9991282522678375, 'rewards/toxicity_reward_function/std': 0.0002581127337180078, 'reward': 0.9991282522678375, 'reward_std': 0.00019674682698678225, 'frac_reward_zero_std': 0.0, 'entropy': 1.0360798239707947, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.63}\n",
            "{'loss': 0.0511, 'grad_norm': 0.0, 'learning_rate': 1.7742883068638445e-07, 'num_tokens': 845740.0, 'completions/mean_length': 71.90625, 'completions/min_length': 27.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.28125, 'completions/mean_terminated_length': 50.59615516662598, 'completions/min_terminated_length': 27.5, 'completions/max_terminated_length': 80.0, 'rewards/toxicity_reward_function/mean': 0.999141126871109, 'rewards/toxicity_reward_function/std': 0.0001861385680967942, 'reward': 0.999141126871109, 'reward_std': 0.00016064431110862643, 'frac_reward_zero_std': 0.0, 'entropy': 1.0716024041175842, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.64}\n",
            "{'loss': -0.0072, 'grad_norm': 0.0, 'learning_rate': 1.6809245510957666e-07, 'num_tokens': 859818.0, 'completions/mean_length': 62.0625, 'completions/min_length': 22.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.1875, 'completions/mean_terminated_length': 46.791669845581055, 'completions/min_terminated_length': 22.0, 'completions/max_terminated_length': 79.5, 'rewards/toxicity_reward_function/mean': 0.9991546273231506, 'rewards/toxicity_reward_function/std': 0.00017815924366004765, 'reward': 0.9991546273231506, 'reward_std': 0.00014074808859732002, 'frac_reward_zero_std': 0.0, 'entropy': 1.1485376060009003, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.65}\n",
            "{'loss': -0.0301, 'grad_norm': 0.0, 'learning_rate': 1.5888237503021257e-07, 'num_tokens': 875409.0, 'completions/mean_length': 82.71875, 'completions/min_length': 32.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.34375, 'completions/mean_terminated_length': 62.46154022216797, 'completions/min_terminated_length': 32.5, 'completions/max_terminated_length': 119.0, 'rewards/toxicity_reward_function/mean': 0.999112993478775, 'rewards/toxicity_reward_function/std': 0.00028962221404071897, 'reward': 0.999112993478775, 'reward_std': 0.0002347659828956239, 'frac_reward_zero_std': 0.0, 'entropy': 1.1387920677661896, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.66}\n",
            "{'loss': -0.0008, 'grad_norm': 0.0, 'learning_rate': 1.498127917242148e-07, 'num_tokens': 891646.0, 'completions/mean_length': 72.78125, 'completions/min_length': 26.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.3125, 'completions/mean_terminated_length': 48.209402084350586, 'completions/min_terminated_length': 26.0, 'completions/max_terminated_length': 95.5, 'rewards/toxicity_reward_function/mean': 0.989960640668869, 'rewards/toxicity_reward_function/std': 0.036685535407741554, 'reward': 0.989960640668869, 'reward_std': 0.01840667256328743, 'frac_reward_zero_std': 0.0, 'entropy': 1.0828556418418884, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.67}\n",
            "{'loss': 0.0071, 'grad_norm': 0.0, 'learning_rate': 1.4089768983166441e-07, 'num_tokens': 904525.0, 'completions/mean_length': 62.71875, 'completions/min_length': 29.0, 'completions/max_length': 98.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 40.03125, 'completions/min_terminated_length': 29.0, 'completions/max_terminated_length': 60.0, 'rewards/toxicity_reward_function/mean': 0.9990699589252472, 'rewards/toxicity_reward_function/std': 0.0003199990896973759, 'reward': 0.9990699589252472, 'reward_std': 0.00018744042608886957, 'frac_reward_zero_std': 0.0, 'entropy': 1.132563829421997, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.69}\n",
            " 69%|██████▊   | 122/178 [42:51<12:25, 13.31s/it]\n",
            " 69%|██████▉   | 123/178 [43:06<12:33, 13.70s/it]\n",
            " 70%|██████▉   | 124/178 [43:20<12:29, 13.87s/it]\n",
            "                                                 \n",
            "\n",
            " 70%|██████▉   | 124/178 [43:20<12:29, 13.87s/it]\n",
            " 70%|███████   | 125/178 [43:29<11:03, 12.51s/it]\n",
            " 71%|███████   | 126/178 [43:44<11:23, 13.15s/it]\n",
            "                                                 \n",
            "\n",
            " 71%|███████   | 126/178 [43:44<11:23, 13.15s/it]\n",
            " 71%|███████▏  | 127/178 [43:59<11:33, 13.60s/it]\n",
            " 72%|███████▏  | 128/178 [44:13<11:37, 13.95s/it]\n",
            "                                                 \n",
            "\n",
            " 72%|███████▏  | 128/178 [44:13<11:37, 13.95s/it]\n",
            " 72%|███████▏  | 129/178 [44:28<11:35, 14.19s/it]\n",
            " 73%|███████▎  | 130/178 [44:43<11:29, 14.36s/it]\n",
            "                                                 \n",
            "\n",
            " 73%|███████▎  | 130/178 [44:43<11:29, 14.36s/it]\n",
            " 74%|███████▎  | 131/178 [44:58<11:19, 14.46s/it]\n",
            " 74%|███████▍  | 132/178 [45:12<11:09, 14.56s/it]\n",
            "                                                 \n",
            "\n",
            " 74%|███████▍  | 132/178 [45:12<11:09, 14.56s/it]\n",
            " 75%|███████▍  | 133/178 [45:27<10:57, 14.62s/it]\n",
            " 75%|███████▌  | 134/178 [45:42<10:43, 14.63s/it]\n",
            "                                                 \n",
            "\n",
            " 75%|███████▌  | 134/178 [45:42<10:43, 14.63s/it]\n",
            " 76%|███████▌  | 135/178 [45:56<10:29, 14.65s/it]\n",
            " 76%|███████▋  | 136/178 [46:11<10:16, 14.67s/it]\n",
            "                                                 \n",
            "\n",
            " 76%|███████▋  | 136/178 [46:11<10:16, 14.67s/it]\n",
            " 77%|███████▋  | 137/178 [46:26<10:02, 14.69s/it]\n",
            " 78%|███████▊  | 138/178 [46:41<09:47, 14.68s/it]\n",
            "                                                 \n",
            "\n",
            " 78%|███████▊  | 138/178 [46:41<09:47, 14.68s/it]\n",
            " 78%|███████▊  | 139/178 [46:55<09:34, 14.74s/it]\n",
            " 79%|███████▊  | 140/178 [47:10<09:19, 14.73s/it]\n",
            "                                                 \n",
            "\n",
            " 79%|███████▊  | 140/178 [47:10<09:19, 14.73s/it]\n",
            " 79%|███████▉  | 141/178 [47:25<09:06, 14.77s/it]\n",
            " 80%|███████▉  | 142/178 [47:35<07:55, 13.22s/it]\n",
            "                                                 \n",
            "\n",
            " 80%|███████▉  | 142/178 [47:35<07:55, 13.22s/it]\n",
            " 80%|████████  | 143/178 [47:45<07:15, 12.45s/it]\n",
            " 81%|████████  | 144/178 [48:00<07:26, 13.13s/it]\n",
            "                                                 \n",
            "{'loss': 0.0376, 'grad_norm': 0.0, 'learning_rate': 1.3215081579350056e-07, 'num_tokens': 922269.0, 'completions/mean_length': 93.0, 'completions/min_length': 66.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.46875, 'completions/mean_terminated_length': 82.10714340209961, 'completions/min_terminated_length': 66.0, 'completions/max_terminated_length': 101.5, 'rewards/toxicity_reward_function/mean': 0.9936289191246033, 'rewards/toxicity_reward_function/std': 0.021501339942915365, 'reward': 0.9936289191246033, 'reward_std': 0.010918943240540102, 'frac_reward_zero_std': 0.0, 'entropy': 1.1111255586147308, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.7}\n",
            "{'loss': -0.0384, 'grad_norm': 0.0, 'learning_rate': 1.2358565665550387e-07, 'num_tokens': 933669.0, 'completions/mean_length': 62.875, 'completions/min_length': 17.5, 'completions/max_length': 103.5, 'completions/clipped_ratio': 0.1875, 'completions/mean_terminated_length': 48.39999961853027, 'completions/min_terminated_length': 17.5, 'completions/max_terminated_length': 95.0, 'rewards/toxicity_reward_function/mean': 0.9992275834083557, 'rewards/toxicity_reward_function/std': 0.00014593402011087164, 'reward': 0.9992275834083557, 'reward_std': 0.00013217301602708176, 'frac_reward_zero_std': 0.0, 'entropy': 0.9871028959751129, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.71}\n",
            "{'loss': 0.0046, 'grad_norm': 0.0, 'learning_rate': 1.1521541927224993e-07, 'num_tokens': 947815.0, 'completions/mean_length': 74.1875, 'completions/min_length': 26.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.375, 'completions/mean_terminated_length': 40.60416793823242, 'completions/min_terminated_length': 26.0, 'completions/max_terminated_length': 61.5, 'rewards/toxicity_reward_function/mean': 0.9990440309047699, 'rewards/toxicity_reward_function/std': 0.0005055543879279867, 'reward': 0.9990440309047699, 'reward_std': 0.00035355529689695686, 'frac_reward_zero_std': 0.0, 'entropy': 1.2293433547019958, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.72}\n",
            "{'loss': 0.0387, 'grad_norm': 0.0, 'learning_rate': 1.0705300994309696e-07, 'num_tokens': 965875.0, 'completions/mean_length': 90.125, 'completions/min_length': 30.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.4375, 'completions/mean_terminated_length': 62.375, 'completions/min_terminated_length': 30.0, 'completions/max_terminated_length': 107.0, 'rewards/toxicity_reward_function/mean': 0.9966400563716888, 'rewards/toxicity_reward_function/std': 0.009694644584669732, 'reward': 0.9966400563716888, 'reward_std': 0.005006500708987005, 'frac_reward_zero_std': 0.0, 'entropy': 1.222056731581688, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.73}\n",
            "{'loss': 0.0072, 'grad_norm': 0.0, 'learning_rate': 9.911101451160714e-08, 'num_tokens': 980468.0, 'completions/mean_length': 67.90625, 'completions/min_length': 22.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.28125, 'completions/mean_terminated_length': 41.09166717529297, 'completions/min_terminated_length': 22.5, 'completions/max_terminated_length': 73.5, 'rewards/toxicity_reward_function/mean': 0.9990532994270325, 'rewards/toxicity_reward_function/std': 0.0002570253454905469, 'reward': 0.9990532994270325, 'reward_std': 0.000147649956488749, 'frac_reward_zero_std': 0.0, 'entropy': 0.9647993892431259, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.74}\n",
            "{'loss': -0.0051, 'grad_norm': 0.0, 'learning_rate': 9.140167895908865e-08, 'num_tokens': 998775.0, 'completions/mean_length': 104.21875, 'completions/min_length': 35.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.59375, 'completions/mean_terminated_length': 68.88095474243164, 'completions/min_terminated_length': 35.0, 'completions/max_terminated_length': 115.5, 'rewards/toxicity_reward_function/mean': 0.9987152218818665, 'rewards/toxicity_reward_function/std': 0.0011546041059773415, 'reward': 0.9987152218818665, 'reward_std': 0.0006292633770499378, 'frac_reward_zero_std': 0.0, 'entropy': 1.2953968346118927, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.75}\n",
            "{'loss': 0.0373, 'grad_norm': 0.0, 'learning_rate': 8.393689052217964e-08, 'num_tokens': 1014508.0, 'completions/mean_length': 82.40625, 'completions/min_length': 17.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.34375, 'completions/mean_terminated_length': 59.11111068725586, 'completions/min_terminated_length': 17.5, 'completions/max_terminated_length': 113.5, 'rewards/toxicity_reward_function/mean': 0.9989060759544373, 'rewards/toxicity_reward_function/std': 0.0008846385317156091, 'reward': 0.9989060759544373, 'reward_std': 0.00045399229566100985, 'frac_reward_zero_std': 0.0, 'entropy': 0.9686459302902222, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.76}\n",
            "{'loss': 0.0018, 'grad_norm': 0.0, 'learning_rate': 7.672815936359105e-08, 'num_tokens': 1029730.0, 'completions/mean_length': 75.1875, 'completions/min_length': 34.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.375, 'completions/mean_terminated_length': 42.16666793823242, 'completions/min_terminated_length': 34.0, 'completions/max_terminated_length': 51.5, 'rewards/toxicity_reward_function/mean': 0.9992173910140991, 'rewards/toxicity_reward_function/std': 0.00018730007286649197, 'reward': 0.9992173910140991, 'reward_std': 0.0001326475030509755, 'frac_reward_zero_std': 0.0, 'entropy': 1.0489525645971298, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.78}\n",
            "{'loss': 0.0003, 'grad_norm': 0.0, 'learning_rate': 6.978660082427029e-08, 'num_tokens': 1046300.0, 'completions/mean_length': 83.8125, 'completions/min_length': 25.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.46875, 'completions/mean_terminated_length': 46.10000038146973, 'completions/min_terminated_length': 25.0, 'completions/max_terminated_length': 68.0, 'rewards/toxicity_reward_function/mean': 0.9985450506210327, 'rewards/toxicity_reward_function/std': 0.0022203837579581887, 'reward': 0.9985450506210327, 'reward_std': 0.0012968363735126331, 'frac_reward_zero_std': 0.0, 'entropy': 1.1480762213468552, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.79}\n",
            "{'loss': 0.0114, 'grad_norm': 0.0, 'learning_rate': 6.312291828435076e-08, 'num_tokens': 1059633.0, 'completions/mean_length': 52.28125, 'completions/min_length': 30.0, 'completions/max_length': 104.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 41.70833396911621, 'completions/min_terminated_length': 30.0, 'completions/max_terminated_length': 70.0, 'rewards/toxicity_reward_function/mean': 0.9992135167121887, 'rewards/toxicity_reward_function/std': 0.0001248382977792062, 'reward': 0.9992135167121887, 'reward_std': 0.0001087334894691594, 'frac_reward_zero_std': 0.0, 'entropy': 1.1357316672801971, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.8}\n",
            "{'loss': -0.0162, 'grad_norm': 0.0, 'learning_rate': 5.674738665931575e-08, 'num_tokens': 1074467.0, 'completions/mean_length': 64.4375, 'completions/min_length': 27.0, 'completions/max_length': 109.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 56.13541793823242, 'completions/min_terminated_length': 27.0, 'completions/max_terminated_length': 108.0, 'rewards/toxicity_reward_function/mean': 0.9991982281208038, 'rewards/toxicity_reward_function/std': 0.00014430035662371665, 'reward': 0.9991982281208038, 'reward_std': 0.00011794264719355851, 'frac_reward_zero_std': 0.0, 'entropy': 1.0626250654459, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.81}\n",
            " 81%|████████  | 144/178 [48:00<07:26, 13.13s/it]\n",
            " 81%|████████▏ | 145/178 [48:15<07:33, 13.75s/it]\n",
            " 82%|████████▏ | 146/178 [48:30<07:28, 14.03s/it]\n",
            "                                                 \n",
            "\n",
            " 82%|████████▏ | 146/178 [48:30<07:28, 14.03s/it]\n",
            " 83%|████████▎ | 147/178 [48:44<07:17, 14.11s/it]\n",
            " 83%|████████▎ | 148/178 [48:59<07:08, 14.27s/it]\n",
            "                                                 \n",
            "\n",
            " 83%|████████▎ | 148/178 [48:59<07:08, 14.27s/it]\n",
            " 84%|████████▎ | 149/178 [49:14<06:57, 14.39s/it]\n",
            " 84%|████████▍ | 150/178 [49:28<06:45, 14.47s/it]\n",
            "                                                 \n",
            "\n",
            " 84%|████████▍ | 150/178 [49:28<06:45, 14.47s/it]\n",
            " 85%|████████▍ | 151/178 [49:43<06:32, 14.54s/it]\n",
            " 85%|████████▌ | 152/178 [49:57<06:15, 14.43s/it]\n",
            "                                                 \n",
            "\n",
            " 85%|████████▌ | 152/178 [49:57<06:15, 14.43s/it]\n",
            " 86%|████████▌ | 153/178 [50:12<06:03, 14.54s/it]\n",
            " 87%|████████▋ | 154/178 [50:27<05:49, 14.58s/it]\n",
            "                                                 \n",
            "\n",
            " 87%|████████▋ | 154/178 [50:27<05:49, 14.58s/it]\n",
            " 87%|████████▋ | 155/178 [50:34<04:48, 12.56s/it]\n",
            " 88%|████████▊ | 156/178 [50:49<04:50, 13.20s/it]\n",
            "                                                 \n",
            "\n",
            " 88%|████████▊ | 156/178 [50:49<04:50, 13.20s/it]\n",
            " 88%|████████▊ | 157/178 [51:03<04:43, 13.49s/it]\n",
            " 89%|████████▉ | 158/178 [51:18<04:36, 13.84s/it]\n",
            "                                                 \n",
            "\n",
            " 89%|████████▉ | 158/178 [51:18<04:36, 13.84s/it]\n",
            " 89%|████████▉ | 159/178 [51:33<04:28, 14.12s/it]\n",
            " 90%|████████▉ | 160/178 [51:47<04:17, 14.32s/it]\n",
            "                                                 \n",
            "\n",
            " 90%|████████▉ | 160/178 [51:47<04:17, 14.32s/it]\n",
            "{'loss': 0.0103, 'grad_norm': 0.0, 'learning_rate': 5.066983655682325e-08, 'num_tokens': 1088638.0, 'completions/mean_length': 70.84375, 'completions/min_length': 22.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.28125, 'completions/mean_terminated_length': 46.587501525878906, 'completions/min_terminated_length': 22.5, 'completions/max_terminated_length': 89.0, 'rewards/toxicity_reward_function/mean': 0.9991625845432281, 'rewards/toxicity_reward_function/std': 0.0002537419932195917, 'reward': 0.9991625845432281, 'reward_std': 0.00015652712318114936, 'frac_reward_zero_std': 0.0, 'entropy': 1.1961580514907837, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.82}\n",
            "{'loss': -0.0456, 'grad_norm': 0.0, 'learning_rate': 4.48996391186216e-08, 'num_tokens': 1105712.0, 'completions/mean_length': 92.5625, 'completions/min_length': 34.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.53125, 'completions/mean_terminated_length': 57.41666603088379, 'completions/min_terminated_length': 34.0, 'completions/max_terminated_length': 88.0, 'rewards/toxicity_reward_function/mean': 0.9970363676548004, 'rewards/toxicity_reward_function/std': 0.008400788778089918, 'reward': 0.9970363676548004, 'reward_std': 0.004273958213161677, 'frac_reward_zero_std': 0.0, 'entropy': 1.3826351761817932, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.83}\n",
            "{'loss': 0.0027, 'grad_norm': 0.0, 'learning_rate': 3.944569157092839e-08, 'num_tokens': 1122194.0, 'completions/mean_length': 78.9375, 'completions/min_length': 16.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.375, 'completions/mean_terminated_length': 51.08333396911621, 'completions/min_terminated_length': 16.5, 'completions/max_terminated_length': 101.0, 'rewards/toxicity_reward_function/mean': 0.9990206956863403, 'rewards/toxicity_reward_function/std': 0.0003420259599806741, 'reward': 0.9990206956863403, 'reward_std': 0.0002606184425530955, 'frac_reward_zero_std': 0.0, 'entropy': 1.242275059223175, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.84}\n",
            "{'loss': 0.0158, 'grad_norm': 0.0, 'learning_rate': 3.431640350555204e-08, 'num_tokens': 1139055.0, 'completions/mean_length': 89.90625, 'completions/min_length': 30.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.5, 'completions/mean_terminated_length': 66.95833396911621, 'completions/min_terminated_length': 30.5, 'completions/max_terminated_length': 83.5, 'rewards/toxicity_reward_function/mean': 0.9989705085754395, 'rewards/toxicity_reward_function/std': 0.0005387149285525084, 'reward': 0.9989705085754395, 'reward_std': 0.0003638172638602555, 'frac_reward_zero_std': 0.0, 'entropy': 1.2223066687583923, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.85}\n",
            "{'loss': 0.0259, 'grad_norm': 0.0, 'learning_rate': 2.9519683912911263e-08, 'num_tokens': 1155122.0, 'completions/mean_length': 83.34375, 'completions/min_length': 29.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.375, 'completions/mean_terminated_length': 59.27083396911621, 'completions/min_terminated_length': 29.0, 'completions/max_terminated_length': 97.5, 'rewards/toxicity_reward_function/mean': 0.9853448271751404, 'rewards/toxicity_reward_function/std': 0.043467401643283665, 'reward': 0.9853448271751404, 'reward_std': 0.02072585336281918, 'frac_reward_zero_std': 0.0, 'entropy': 1.289974421262741, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.87}\n",
            "{'loss': 0.0089, 'grad_norm': 0.0, 'learning_rate': 2.5062928986944676e-08, 'num_tokens': 1169813.0, 'completions/mean_length': 67.34375, 'completions/min_length': 27.0, 'completions/max_length': 96.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 50.71875, 'completions/min_terminated_length': 27.0, 'completions/max_terminated_length': 87.0, 'rewards/toxicity_reward_function/mean': 0.9992030262947083, 'rewards/toxicity_reward_function/std': 0.00014765694868401624, 'reward': 0.9992030262947083, 'reward_std': 0.00011119664850411937, 'frac_reward_zero_std': 0.0, 'entropy': 1.084833338856697, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.88}\n",
            "{'loss': 0.0039, 'grad_norm': 0.0, 'learning_rate': 2.0953010720716035e-08, 'num_tokens': 1185827.0, 'completions/mean_length': 96.0625, 'completions/min_length': 76.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.59375, 'completions/mean_terminated_length': 82.66666793823242, 'completions/min_terminated_length': 76.5, 'completions/max_terminated_length': 89.0, 'rewards/toxicity_reward_function/mean': 0.9991409182548523, 'rewards/toxicity_reward_function/std': 0.00016825756756588817, 'reward': 0.9991409182548523, 'reward_std': 0.00012711764065898024, 'frac_reward_zero_std': 0.0, 'entropy': 1.1412347257137299, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.89}\n",
            "{'loss': -0.0106, 'grad_norm': 0.0, 'learning_rate': 1.7196266310299108e-08, 'num_tokens': 1202593.0, 'completions/mean_length': 87.1875, 'completions/min_length': 17.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.4375, 'completions/mean_terminated_length': 55.4444465637207, 'completions/min_terminated_length': 17.0, 'completions/max_terminated_length': 114.5, 'rewards/toxicity_reward_function/mean': 0.9991040825843811, 'rewards/toxicity_reward_function/std': 0.00018405169248580933, 'reward': 0.9991040825843811, 'reward_std': 0.0001660701964283362, 'frac_reward_zero_std': 0.0, 'entropy': 1.1794167757034302, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.9}\n",
            "\n",
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  3%|▎         | 2/76 [00:07<04:19,  3.51s/it]\u001b[A\n",
            "\n",
            "  4%|▍         | 3/76 [00:19<08:43,  7.18s/it]\u001b[A\n",
            "\n",
            "  5%|▌         | 4/76 [00:31<10:56,  9.12s/it]\u001b[A\n",
            "\n",
            "  7%|▋         | 5/76 [00:37<09:29,  8.02s/it]\u001b[A\n",
            "\n",
            "  8%|▊         | 6/76 [00:49<11:00,  9.43s/it]\u001b[A\n",
            "\n",
            "  9%|▉         | 7/76 [01:02<12:06, 10.53s/it]\u001b[A\n",
            "\n",
            " 11%|█         | 8/76 [01:15<12:42, 11.21s/it]\u001b[A\n",
            "\n",
            " 12%|█▏        | 9/76 [01:28<13:04, 11.71s/it]\u001b[A\n",
            "\n",
            " 13%|█▎        | 10/76 [01:40<13:04, 11.89s/it]\u001b[A\n",
            "\n",
            " 14%|█▍        | 11/76 [01:53<13:10, 12.16s/it]\u001b[A\n",
            "\n",
            " 16%|█▌        | 12/76 [02:06<13:10, 12.35s/it]\u001b[A\n",
            "\n",
            " 17%|█▋        | 13/76 [02:18<12:58, 12.36s/it]\u001b[A\n",
            "\n",
            " 18%|█▊        | 14/76 [02:30<12:47, 12.38s/it]\u001b[A\n",
            "\n",
            " 20%|█▉        | 15/76 [02:43<12:42, 12.51s/it]\u001b[A\n",
            "\n",
            " 21%|██        | 16/76 [02:56<12:35, 12.59s/it]\u001b[A\n",
            "\n",
            " 22%|██▏       | 17/76 [03:09<12:21, 12.56s/it]\u001b[A\n",
            "\n",
            " 24%|██▎       | 18/76 [03:14<10:04, 10.42s/it]\u001b[A\n",
            "\n",
            " 25%|██▌       | 19/76 [03:27<10:36, 11.17s/it]\u001b[A\n",
            "\n",
            " 26%|██▋       | 20/76 [03:40<10:55, 11.70s/it]\u001b[A\n",
            "\n",
            " 28%|██▊       | 21/76 [03:53<11:03, 12.06s/it]\u001b[A\n",
            "\n",
            " 29%|██▉       | 22/76 [04:06<11:03, 12.29s/it]\u001b[A\n",
            "\n",
            " 30%|███       | 23/76 [04:17<10:41, 12.10s/it]\u001b[A\n",
            "\n",
            " 32%|███▏      | 24/76 [04:30<10:35, 12.23s/it]\u001b[A\n",
            "\n",
            " 33%|███▎      | 25/76 [04:37<09:01, 10.62s/it]\u001b[A\n",
            "\n",
            " 34%|███▍      | 26/76 [04:49<09:22, 11.26s/it]\u001b[A\n",
            "\n",
            " 36%|███▌      | 27/76 [05:02<09:33, 11.70s/it]\u001b[A\n",
            "\n",
            " 37%|███▋      | 28/76 [05:14<09:29, 11.86s/it]\u001b[A\n",
            "\n",
            " 38%|███▊      | 29/76 [05:27<09:21, 11.96s/it]\u001b[A\n",
            "\n",
            " 39%|███▉      | 30/76 [05:39<09:19, 12.16s/it]\u001b[A\n",
            "\n",
            " 41%|████      | 31/76 [05:52<09:13, 12.31s/it]\u001b[A\n",
            "\n",
            " 42%|████▏     | 32/76 [06:04<09:00, 12.29s/it]\u001b[A\n",
            "\n",
            " 43%|████▎     | 33/76 [06:11<07:41, 10.74s/it]\u001b[A\n",
            "\n",
            " 45%|████▍     | 34/76 [06:23<07:50, 11.21s/it]\u001b[A\n",
            "\n",
            " 46%|████▌     | 35/76 [06:36<07:52, 11.53s/it]\u001b[A\n",
            "\n",
            " 47%|████▋     | 36/76 [06:49<07:55, 11.89s/it]\u001b[A\n",
            "\n",
            " 49%|████▊     | 37/76 [07:01<07:52, 12.11s/it]\u001b[A\n",
            "\n",
            " 50%|█████     | 38/76 [07:14<07:46, 12.29s/it]\u001b[A\n",
            "\n",
            " 51%|█████▏    | 39/76 [07:27<07:39, 12.43s/it]\u001b[A\n",
            "\n",
            " 53%|█████▎    | 40/76 [07:39<07:31, 12.55s/it]\u001b[A\n",
            "\n",
            " 54%|█████▍    | 41/76 [07:52<07:21, 12.60s/it]\u001b[A\n",
            "\n",
            " 55%|█████▌    | 42/76 [08:05<07:10, 12.66s/it]\u001b[A\n",
            "\n",
            " 57%|█████▋    | 43/76 [08:18<06:59, 12.71s/it]\u001b[A\n",
            "\n",
            " 58%|█████▊    | 44/76 [08:30<06:43, 12.59s/it]\u001b[A\n",
            "\n",
            " 59%|█████▉    | 45/76 [08:43<06:31, 12.64s/it]\u001b[A\n",
            "\n",
            " 61%|██████    | 46/76 [08:50<05:30, 11.02s/it]\u001b[A\n",
            "\n",
            " 62%|██████▏   | 47/76 [08:56<04:33,  9.44s/it]\u001b[A\n",
            "\n",
            " 63%|██████▎   | 48/76 [09:09<04:52, 10.46s/it]\u001b[A\n",
            "\n",
            " 64%|██████▍   | 49/76 [09:21<04:58, 11.04s/it]\u001b[A\n",
            "\n",
            " 66%|██████▌   | 50/76 [09:34<05:00, 11.57s/it]\u001b[A\n",
            "\n",
            " 67%|██████▋   | 51/76 [09:47<04:57, 11.92s/it]\u001b[A\n",
            "\n",
            " 68%|██████▊   | 52/76 [09:59<04:50, 12.10s/it]\u001b[A\n",
            "\n",
            " 70%|██████▉   | 53/76 [10:12<04:40, 12.19s/it]\u001b[A\n",
            "\n",
            " 71%|███████   | 54/76 [10:24<04:32, 12.37s/it]\u001b[A\n",
            "\n",
            " 72%|███████▏  | 55/76 [10:37<04:19, 12.35s/it]\u001b[A\n",
            "\n",
            " 74%|███████▎  | 56/76 [10:49<04:09, 12.46s/it]\u001b[A\n",
            "\n",
            " 75%|███████▌  | 57/76 [11:02<03:56, 12.44s/it]\u001b[A\n",
            "\n",
            " 76%|███████▋  | 58/76 [11:14<03:45, 12.54s/it]\u001b[A\n",
            "\n",
            " 78%|███████▊  | 59/76 [11:21<03:01, 10.69s/it]\u001b[A\n",
            "\n",
            " 79%|███████▉  | 60/76 [11:34<03:01, 11.33s/it]\u001b[A\n",
            "\n",
            " 80%|████████  | 61/76 [11:46<02:56, 11.76s/it]\u001b[A\n",
            "\n",
            " 82%|████████▏ | 62/76 [11:59<02:46, 11.92s/it]\u001b[A\n",
            "\n",
            " 83%|████████▎ | 63/76 [12:11<02:37, 12.13s/it]\u001b[A\n",
            "\n",
            " 84%|████████▍ | 64/76 [12:24<02:28, 12.34s/it]\u001b[A\n",
            "\n",
            " 86%|████████▌ | 65/76 [12:31<01:56, 10.55s/it]\u001b[A\n",
            "\n",
            " 87%|████████▋ | 66/76 [12:43<01:50, 11.09s/it]\u001b[A\n",
            "\n",
            " 88%|████████▊ | 67/76 [12:56<01:44, 11.62s/it]\u001b[A\n",
            "\n",
            " 89%|████████▉ | 68/76 [13:08<01:35, 11.94s/it]\u001b[A\n",
            "\n",
            " 91%|█████████ | 69/76 [13:21<01:24, 12.00s/it]\u001b[A\n",
            "\n",
            " 92%|█████████▏| 70/76 [13:33<01:12, 12.10s/it]\u001b[A\n",
            "\n",
            " 93%|█████████▎| 71/76 [13:41<00:54, 10.97s/it]\u001b[A\n",
            "\n",
            " 95%|█████████▍| 72/76 [13:54<00:45, 11.38s/it]\u001b[A\n",
            "\n",
            " 96%|█████████▌| 73/76 [14:06<00:35, 11.77s/it]\u001b[A\n",
            "\n",
            " 97%|█████████▋| 74/76 [14:19<00:23, 11.93s/it]\u001b[A\n",
            "\n",
            " 99%|█████████▊| 75/76 [14:31<00:12, 12.18s/it]\u001b[A\n",
            "\n",
            "100%|██████████| 76/76 [14:44<00:00, 12.34s/it]\u001b[A\n",
            "                                                 \n",
            "\n",
            "                                               \n",
            "\u001b[A\n",
            " 90%|████████▉ | 160/178 [1:06:44<04:17, 14.32s/it]\n",
            "\n",
            "100%|██████████| 76/76 [14:44<00:00, 12.34s/it]\u001b[A\n",
            "\n",
            "                                               \u001b[A/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n",
            "\n",
            " 90%|█████████ | 161/178 [1:07:00<1:20:24, 283.79s/it]\n",
            " 91%|█████████ | 162/178 [1:07:14<54:05, 202.85s/it]  \n",
            "                                                    \n",
            "\n",
            " 91%|█████████ | 162/178 [1:07:14<54:05, 202.85s/it]\n",
            " 92%|█████████▏| 163/178 [1:07:29<36:35, 146.39s/it]\n",
            " 92%|█████████▏| 164/178 [1:07:43<24:55, 106.85s/it]\n",
            "                                                    \n",
            "\n",
            " 92%|█████████▏| 164/178 [1:07:43<24:55, 106.85s/it]\n",
            " 93%|█████████▎| 165/178 [1:07:58<17:09, 79.22s/it] \n",
            " 93%|█████████▎| 166/178 [1:08:13<11:58, 59.87s/it]\n",
            "                                                   \n",
            "\n",
            " 93%|█████████▎| 166/178 [1:08:13<11:58, 59.87s/it]\n",
            " 94%|█████████▍| 167/178 [1:08:20<08:05, 44.12s/it]\n",
            " 94%|█████████▍| 168/178 [1:08:35<05:53, 35.30s/it]\n",
            "                                                   \n",
            "\n",
            " 94%|█████████▍| 168/178 [1:08:35<05:53, 35.30s/it]\n",
            " 95%|█████████▍| 169/178 [1:08:50<04:22, 29.14s/it]\n",
            " 96%|█████████▌| 170/178 [1:09:03<03:16, 24.52s/it]\n",
            "                                                   \n",
            "\n",
            " 96%|█████████▌| 170/178 [1:09:03<03:16, 24.52s/it]\n",
            " 96%|█████████▌| 171/178 [1:09:18<02:30, 21.55s/it]\n",
            " 97%|█████████▋| 172/178 [1:09:33<01:57, 19.53s/it]\n",
            "                                                   \n",
            "\n",
            " 97%|█████████▋| 172/178 [1:09:33<01:57, 19.53s/it]\n",
            " 97%|█████████▋| 173/178 [1:09:48<01:30, 18.12s/it]\n",
            " 98%|█████████▊| 174/178 [1:10:02<01:08, 17.12s/it]\n",
            "                                                   \n",
            "\n",
            " 98%|█████████▊| 174/178 [1:10:02<01:08, 17.12s/it]\n",
            " 98%|█████████▊| 175/178 [1:10:17<00:49, 16.44s/it]\n",
            " 99%|█████████▉| 176/178 [1:10:32<00:31, 15.94s/it]\n",
            "                                                   \n",
            "\n",
            " 99%|█████████▉| 176/178 [1:10:32<00:31, 15.94s/it]\n",
            " 99%|█████████▉| 177/178 [1:10:47<00:15, 15.62s/it]\n",
            "100%|██████████| 178/178 [1:11:02<00:00, 15.36s/it]\n",
            "                                                   \n",
            "\n",
            "100%|██████████| 178/178 [1:11:02<00:00, 15.36s/it]\n",
            "                                                   \n",
            "{'eval_loss': -0.0023128297179937363, 'eval_runtime': 896.8811, 'eval_samples_per_second': 0.169, 'eval_steps_per_second': 0.021, 'eval_num_tokens': 1202593.0, 'eval_completions/mean_length': 89.81414473684211, 'eval_completions/min_length': 51.526315789473685, 'eval_completions/max_length': 119.67105263157895, 'eval_completions/clipped_ratio': 0.46710526315789475, 'eval_completions/mean_terminated_length': 59.56308018533807, 'eval_completions/min_terminated_length': 44.78947368421053, 'eval_completions/max_terminated_length': 79.57894736842105, 'eval_rewards/toxicity_reward_function/mean': 0.9974022868432497, 'eval_rewards/toxicity_reward_function/std': 0.004957408843007502, 'eval_reward': 0.9974022868432497, 'eval_reward_std': 0.0035174106892794186, 'eval_frac_reward_zero_std': 0.0, 'eval_entropy': 1.1930317659127085, 'eval_clip_ratio/low_mean': 0.0, 'eval_clip_ratio/low_min': 0.0, 'eval_clip_ratio/high_mean': 0.0, 'eval_clip_ratio/high_max': 0.0, 'eval_clip_ratio/region_mean': 0.0, 'epoch': 0.9}\n",
            "{'loss': 0.0199, 'grad_norm': 0.0, 'learning_rate': 1.3798488383280489e-08, 'num_tokens': 1217555.0, 'completions/mean_length': 61.0625, 'completions/min_length': 27.0, 'completions/max_length': 125.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 50.14583396911621, 'completions/min_terminated_length': 27.0, 'completions/max_terminated_length': 89.5, 'rewards/toxicity_reward_function/mean': 0.9990842342376709, 'rewards/toxicity_reward_function/std': 0.0002910041657742113, 'reward': 0.9990842342376709, 'reward_std': 0.00022472147247754037, 'frac_reward_zero_std': 0.0, 'entropy': 1.146664336323738, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.91}\n",
            "{'loss': 0.0573, 'grad_norm': 0.0, 'learning_rate': 1.0764916066947794e-08, 'num_tokens': 1231477.0, 'completions/mean_length': 72.9375, 'completions/min_length': 21.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.34375, 'completions/mean_terminated_length': 44.066667556762695, 'completions/min_terminated_length': 21.0, 'completions/max_terminated_length': 81.0, 'rewards/toxicity_reward_function/mean': 0.9990625977516174, 'rewards/toxicity_reward_function/std': 0.00033164706837851554, 'reward': 0.9990625977516174, 'reward_std': 0.0002238917222712189, 'frac_reward_zero_std': 0.0, 'entropy': 1.241653561592102, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.92}\n",
            "{'loss': -0.0093, 'grad_norm': 0.0, 'learning_rate': 8.100226909935059e-09, 'num_tokens': 1246697.0, 'completions/mean_length': 59.25, 'completions/min_length': 22.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.1875, 'completions/mean_terminated_length': 43.184526443481445, 'completions/min_terminated_length': 22.5, 'completions/max_terminated_length': 76.0, 'rewards/toxicity_reward_function/mean': 0.9992331266403198, 'rewards/toxicity_reward_function/std': 0.00010261626448482275, 'reward': 0.9992331266403198, 'reward_std': 7.96889107732568e-05, 'frac_reward_zero_std': 0.0, 'entropy': 1.0425105839967728, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.93}\n",
            "{'loss': -0.0282, 'grad_norm': 0.0, 'learning_rate': 5.8085296697819035e-09, 'num_tokens': 1262712.0, 'completions/mean_length': 72.09375, 'completions/min_length': 26.0, 'completions/max_length': 94.0, 'completions/clipped_ratio': 0.28125, 'completions/mean_terminated_length': 53.20982360839844, 'completions/min_terminated_length': 26.0, 'completions/max_terminated_length': 82.0, 'rewards/toxicity_reward_function/mean': 0.9826392233371735, 'rewards/toxicity_reward_function/std': 0.0660960254172096, 'reward': 0.9826392233371735, 'reward_std': 0.03316116938367486, 'frac_reward_zero_std': 0.0, 'entropy': 1.1387979388237, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.94}\n",
            "{'loss': -0.0088, 'grad_norm': 0.0, 'learning_rate': 3.8933579775271005e-09, 'num_tokens': 1277029.0, 'completions/mean_length': 71.40625, 'completions/min_length': 24.0, 'completions/max_length': 124.0, 'completions/clipped_ratio': 0.21875, 'completions/mean_terminated_length': 54.07638931274414, 'completions/min_terminated_length': 24.0, 'completions/max_terminated_length': 119.5, 'rewards/toxicity_reward_function/mean': 0.9991022944450378, 'rewards/toxicity_reward_function/std': 0.00024432726786471903, 'reward': 0.9991022944450378, 'reward_std': 0.00018315530905965716, 'frac_reward_zero_std': 0.0, 'entropy': 0.9923274517059326, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.96}\n",
            "{'loss': 0.0032, 'grad_norm': 0.0, 'learning_rate': 2.357664889105687e-09, 'num_tokens': 1294209.0, 'completions/mean_length': 91.375, 'completions/min_length': 37.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.4375, 'completions/mean_terminated_length': 65.22078132629395, 'completions/min_terminated_length': 37.0, 'completions/max_terminated_length': 107.0, 'rewards/toxicity_reward_function/mean': 0.9991664886474609, 'rewards/toxicity_reward_function/std': 0.00016152680473169312, 'reward': 0.9991664886474609, 'reward_std': 0.00011487392475828528, 'frac_reward_zero_std': 0.0, 'entropy': 1.1516852974891663, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.97}\n",
            "{'loss': 0.0048, 'grad_norm': 0.0, 'learning_rate': 1.2038183319507956e-09, 'num_tokens': 1307660.0, 'completions/mean_length': 73.84375, 'completions/min_length': 29.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.3125, 'completions/mean_terminated_length': 49.408334732055664, 'completions/min_terminated_length': 29.5, 'completions/max_terminated_length': 87.5, 'rewards/toxicity_reward_function/mean': 0.9990695714950562, 'rewards/toxicity_reward_function/std': 0.0003165857633575797, 'reward': 0.9990695714950562, 'reward_std': 0.00020581771968863904, 'frac_reward_zero_std': 0.0, 'entropy': 1.1289211511611938, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.98}\n",
            "{'loss': 0.0006, 'grad_norm': 0.0, 'learning_rate': 4.3359745382104405e-10, 'num_tokens': 1323923.0, 'completions/mean_length': 85.34375, 'completions/min_length': 33.5, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.4375, 'completions/mean_terminated_length': 56.484619140625, 'completions/min_terminated_length': 33.5, 'completions/max_terminated_length': 106.0, 'rewards/toxicity_reward_function/mean': 0.9989108443260193, 'rewards/toxicity_reward_function/std': 0.0005158070416655391, 'reward': 0.9989108443260193, 'reward_std': 0.0002645085914991796, 'frac_reward_zero_std': 0.0, 'entropy': 1.2037629783153534, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.99}\n",
            "{'loss': 0.0041, 'grad_norm': 0.0, 'learning_rate': 4.818987948379538e-11, 'num_tokens': 1341155.0, 'completions/mean_length': 82.0, 'completions/min_length': 25.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.34375, 'completions/mean_terminated_length': 56.360578536987305, 'completions/min_terminated_length': 25.0, 'completions/max_terminated_length': 89.5, 'rewards/toxicity_reward_function/mean': 0.9991590976715088, 'rewards/toxicity_reward_function/std': 0.00023096823133528233, 'reward': 0.9991590976715088, 'reward_std': 0.0001412992860423401, 'frac_reward_zero_std': 0.0, 'entropy': 1.1537373661994934, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 1.0}\n",
            "{'train_runtime': 4263.0958, 'train_samples_per_second': 0.167, 'train_steps_per_second': 0.042, 'train_loss': 0.002549536071006167, 'epoch': 1.0}\n",
            "100%|██████████| 178/178 [1:11:03<00:00, 15.36s/it]\n",
            "100%|██████████| 178/178 [1:11:03<00:00, 23.95s/it]\n",
            "2025-11-12 10:37:14,278 - llm_summarize.grpo_alignment - INFO - \n",
            "================================================================================\n",
            "2025-11-12 10:37:14,279 - llm_summarize.grpo_alignment - INFO - GRPO ALIGNMENT COMPLETED\n",
            "2025-11-12 10:37:14,279 - llm_summarize.grpo_alignment - INFO - ================================================================================\n",
            "\n",
            "2025-11-12 10:37:14,279 - llm_summarize.grpo_alignment - INFO - Saving aligned model...\n",
            "2025-11-12 10:37:15,292 - llm_summarize.grpo_alignment - INFO - Model saved to models/grpo_final\n",
            "2025-11-12 10:37:16,290 - llm_summarize.grpo_alignment - INFO - Model also saved to grpo_output\n",
            "wandb: updating run metadata\n",
            "wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml\n",
            "wandb: uploading history steps 2595-2605, summary, console lines 289-289\n",
            "wandb: \n",
            "wandb: Run history:\n",
            "wandb:                eval/clip_ratio/high_max ▁▁\n",
            "wandb:               eval/clip_ratio/high_mean ▁▁\n",
            "wandb:                eval/clip_ratio/low_mean ▁▁\n",
            "wandb:                 eval/clip_ratio/low_min ▁▁\n",
            "wandb:             eval/clip_ratio/region_mean ▁▁\n",
            "wandb:          eval/completions/clipped_ratio █▁\n",
            "wandb:             eval/completions/max_length ▁█\n",
            "wandb:  eval/completions/max_terminated_length ▁█\n",
            "wandb:            eval/completions/mean_length █▁\n",
            "wandb: eval/completions/mean_terminated_length ▁█\n",
            "wandb:                                     +43 ...\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb:                eval/clip_ratio/high_max 0\n",
            "wandb:               eval/clip_ratio/high_mean 0\n",
            "wandb:                eval/clip_ratio/low_mean 0\n",
            "wandb:                 eval/clip_ratio/low_min 0\n",
            "wandb:             eval/clip_ratio/region_mean 0\n",
            "wandb:          eval/completions/clipped_ratio 0.46711\n",
            "wandb:             eval/completions/max_length 119.67105\n",
            "wandb:  eval/completions/max_terminated_length 79.57895\n",
            "wandb:            eval/completions/mean_length 89.81414\n",
            "wandb: eval/completions/mean_terminated_length 59.56308\n",
            "wandb:                                     +48 ...\n",
            "wandb: \n",
            "wandb: 🚀 View run gemma-3-1b-it-grpo-detox at: https://wandb.ai/dmytro-stepanchuk-cs-igor-sikorsky-kyiv-polytechnic-inst/gemma-summarization-detox/runs/gmisrgnr\n",
            "wandb: ⭐️ View project at: https://wandb.ai/dmytro-stepanchuk-cs-igor-sikorsky-kyiv-polytechnic-inst/gemma-summarization-detox\n",
            "wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20251112_092609-gmisrgnr/logs\n",
            "2025-11-12 10:37:18,052 - llm_summarize.grpo_alignment - INFO - \n",
            "================================================================================\n",
            "2025-11-12 10:37:18,052 - llm_summarize.grpo_alignment - INFO - PIPELINE COMPLETED SUCCESSFULLY\n",
            "2025-11-12 10:37:18,052 - llm_summarize.grpo_alignment - INFO - ================================================================================\n",
            "\n",
            "2025-11-12 10:37:18,053 - __main__ - INFO - \n",
            "====================================================================================================\n",
            "2025-11-12 10:37:18,053 - __main__ - INFO - STAGE COMPLETED: GRPO ALIGNMENT\n",
            "2025-11-12 10:37:18,053 - __main__ - INFO - ====================================================================================================\n",
            "\n",
            "2025-11-12 10:37:18,492 - __main__ - INFO - \n",
            "====================================================================================================\n",
            "2025-11-12 10:37:18,492 - __main__ - INFO - STAGE: MODEL EVALUATION\n",
            "2025-11-12 10:37:18,494 - __main__ - INFO - ====================================================================================================\n",
            "\n",
            "2025-11-12 10:37:18,514 - llm_summarize.models_evaluation - INFO - Configuration loaded from config/config.yaml\n",
            "\n",
            "\n",
            "Downloading builder script: 0.00B [00:00, ?B/s]\n",
            "Downloading builder script: 6.27kB [00:00, 13.2MB/s]\n",
            "\n",
            "Downloading builder script: 0.00B [00:00, ?B/s]\n",
            "Downloading builder script: 6.08kB [00:00, 15.7MB/s]\n",
            "2025-11-12 10:37:21,564 - evaluate_modules.metrics.evaluate-measurement--toxicity.2390290fa0bf6d78480143547c6b08f3d4f8805b249df8c7a8e80d0ce8e3778b.toxicity - WARNING - Using default facebook/roberta-hate-speech-dynabench-r4-target checkpoint\n",
            "Device set to use cuda:0\n",
            "2025-11-12 10:37:26,338 - llm_summarize.models_evaluation - INFO - ModelEvaluator initialized successfully\n",
            "2025-11-12 10:37:26,338 - llm_summarize.models_evaluation - INFO - \n",
            "================================================================================\n",
            "2025-11-12 10:37:26,338 - llm_summarize.models_evaluation - INFO - MODEL EVALUATION PIPELINE\n",
            "2025-11-12 10:37:26,338 - llm_summarize.models_evaluation - INFO - ================================================================================\n",
            "\n",
            "2025-11-12 10:37:26,338 - llm_summarize.models_evaluation - INFO - \n",
            "================================================================================\n",
            "2025-11-12 10:37:26,338 - llm_summarize.models_evaluation - INFO - EVALUATING ALL MODELS\n",
            "2025-11-12 10:37:26,338 - llm_summarize.models_evaluation - INFO - ================================================================================\n",
            "\n",
            "2025-11-12 10:37:26,338 - llm_summarize.models_evaluation - INFO - Loading test data...\n",
            "2025-11-12 10:37:26,352 - llm_summarize.models_evaluation - INFO - Loaded 134 test samples from toxic dataset\n",
            "2025-11-12 10:37:26,359 - llm_summarize.models_evaluation - INFO - Sampled 48 test samples for evaluation\n",
            "2025-11-12 10:37:26,359 - llm_summarize.models_evaluation - INFO - Test data ready: 48 samples\n",
            "2025-11-12 10:37:26,359 - llm_summarize.models_evaluation - INFO - \n",
            "================================================================================\n",
            "2025-11-12 10:37:26,359 - llm_summarize.models_evaluation - INFO - Evaluating model: base\n",
            "2025-11-12 10:37:26,359 - llm_summarize.models_evaluation - INFO - ================================================================================\n",
            "\n",
            "2025-11-12 10:37:26,360 - llm_summarize.models_evaluation - INFO - Loading model from google/gemma-3-1b-it...\n",
            "2025-11-12 10:37:28,667 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "2025-11-12 10:37:29,685 - llm_summarize.models_evaluation - INFO - Loaded model from google/gemma-3-1b-it\n",
            "\n",
            "Generating:   0%|          | 0/12 [00:00<?, ?it/s]\n",
            "Generating:   8%|▊         | 1/12 [00:08<01:28,  8.01s/it]\n",
            "Generating:  17%|█▋        | 2/12 [00:15<01:19,  7.94s/it]\n",
            "Generating:  25%|██▌       | 3/12 [00:24<01:13,  8.18s/it]\n",
            "Generating:  33%|███▎      | 4/12 [00:32<01:04,  8.09s/it]\n",
            "Generating:  42%|████▏     | 5/12 [00:40<00:56,  8.02s/it]\n",
            "Generating:  50%|█████     | 6/12 [00:48<00:47,  8.00s/it]\n",
            "Generating:  58%|█████▊    | 7/12 [00:56<00:39,  7.95s/it]\n",
            "Generating:  67%|██████▋   | 8/12 [01:03<00:31,  7.93s/it]\n",
            "Generating:  75%|███████▌  | 9/12 [01:11<00:23,  7.92s/it]\n",
            "Generating:  83%|████████▎ | 10/12 [01:19<00:15,  7.93s/it]\n",
            "Generating:  92%|█████████▏| 11/12 [01:27<00:07,  7.95s/it]\n",
            "Generating: 100%|██████████| 12/12 [01:35<00:00,  7.98s/it]\n",
            "Generating: 100%|██████████| 12/12 [01:35<00:00,  7.98s/it]\n",
            "2025-11-12 10:39:05,490 - llm_summarize.models_evaluation - INFO - Generated 48 summaries\n",
            "2025-11-12 10:39:05,490 - llm_summarize.models_evaluation - INFO - Computing ROUGE scores...\n",
            "2025-11-12 10:39:05,497 - absl - INFO - Using default tokenizer.\n",
            "2025-11-12 10:39:05,662 - llm_summarize.models_evaluation - INFO - Computing toxicity scores...\n",
            "2025-11-12 10:39:06,214 - llm_summarize.models_evaluation - INFO - \n",
            "Results for base:\n",
            "2025-11-12 10:39:06,215 - llm_summarize.models_evaluation - INFO -   ROUGE-1: 0.0885\n",
            "2025-11-12 10:39:06,215 - llm_summarize.models_evaluation - INFO -   ROUGE-2: 0.0104\n",
            "2025-11-12 10:39:06,215 - llm_summarize.models_evaluation - INFO -   ROUGE-L: 0.0876\n",
            "2025-11-12 10:39:06,215 - llm_summarize.models_evaluation - INFO -   ROUGE-Lsum: 0.0878\n",
            "2025-11-12 10:39:06,215 - llm_summarize.models_evaluation - INFO -   Max Toxicity: 0.0336\n",
            "2025-11-12 10:39:06,215 - llm_summarize.models_evaluation - INFO -   Mean Toxicity: 0.0071\n",
            "2025-11-12 10:39:06,222 - llm_summarize.models_evaluation - INFO - Predictions saved to outputs/base_predictions.jsonl\n",
            "2025-11-12 10:39:06,348 - llm_summarize.models_evaluation - INFO - \n",
            "================================================================================\n",
            "2025-11-12 10:39:06,349 - llm_summarize.models_evaluation - INFO - Evaluating model: sft\n",
            "2025-11-12 10:39:06,350 - llm_summarize.models_evaluation - INFO - ================================================================================\n",
            "\n",
            "2025-11-12 10:39:06,351 - llm_summarize.models_evaluation - INFO - Loading model from models/models/sft_final...\n",
            "2025-11-12 10:39:06,352 - llm_summarize.models_evaluation - ERROR - Failed to evaluate sft: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'models/models/sft_final'. Use `repo_type` argument if needed.\n",
            "2025-11-12 10:39:06,352 - llm_summarize.models_evaluation - INFO - \n",
            "================================================================================\n",
            "2025-11-12 10:39:06,352 - llm_summarize.models_evaluation - INFO - Evaluating model: grpo\n",
            "2025-11-12 10:39:06,352 - llm_summarize.models_evaluation - INFO - ================================================================================\n",
            "\n",
            "2025-11-12 10:39:06,352 - llm_summarize.models_evaluation - INFO - Loading model from models/models/grpo_final...\n",
            "2025-11-12 10:39:06,352 - llm_summarize.models_evaluation - ERROR - Failed to evaluate grpo: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'models/models/grpo_final'. Use `repo_type` argument if needed.\n",
            "2025-11-12 10:39:06,359 - llm_summarize.models_evaluation - INFO - \n",
            "Evaluation results saved to outputs/evaluation_results.csv\n",
            "2025-11-12 10:39:06,359 - llm_summarize.models_evaluation - INFO - \n",
            "================================================================================\n",
            "2025-11-12 10:39:06,359 - llm_summarize.models_evaluation - INFO - EVALUATION SUMMARY\n",
            "2025-11-12 10:39:06,359 - llm_summarize.models_evaluation - INFO - ================================================================================\n",
            "\n",
            "2025-11-12 10:39:06,366 - llm_summarize.models_evaluation - INFO - \n",
            "================================================================================\n",
            "2025-11-12 10:39:06,366 - llm_summarize.models_evaluation - INFO - EVALUATION COMPLETED SUCCESSFULLY\n",
            "2025-11-12 10:39:06,366 - llm_summarize.models_evaluation - INFO - ================================================================================\n",
            "\n",
            "2025-11-12 10:39:06,366 - __main__ - INFO - \n",
            "====================================================================================================\n",
            "2025-11-12 10:39:06,366 - __main__ - INFO - STAGE COMPLETED: MODEL EVALUATION\n",
            "2025-11-12 10:39:06,366 - __main__ - INFO - ====================================================================================================\n",
            "\n",
            "2025-11-12 10:39:06,366 - __main__ - INFO - \n",
            "====================================================================================================\n",
            "2025-11-12 10:39:06,366 - __main__ - INFO - PIPELINE COMPLETED SUCCESSFULLY\n",
            "2025-11-12 10:39:06,366 - __main__ - INFO - End time: 2025-11-12 10:39:06\n",
            "2025-11-12 10:39:06,366 - __main__ - INFO - Total duration: 1:13:04.065288\n",
            "2025-11-12 10:39:06,366 - __main__ - INFO - Stages completed: GRPO ALIGNMENT, MODEL EVALUATION\n",
            "2025-11-12 10:39:06,366 - __main__ - INFO - ====================================================================================================\n",
            "\n",
            "model_name           model_path   rouge1   rouge2   rougeL  rougeLsum  max_toxicity  mean_toxicity  num_samples\n",
            "      base google/gemma-3-1b-it 0.088492 0.010417 0.087649   0.087798      0.033614       0.007101           48\n",
            "\n",
            "================================================================================\n",
            "✅ Пайплайн завершен успешно!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "script_path = '/content/project/kyivstar-test-task/scripts/entry_point.py'\n",
        "\n",
        "\n",
        "\n",
        "process = subprocess.Popen(\n",
        "    [sys.executable, script_path, '--stages','eval'],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True,\n",
        "    bufsize=1,\n",
        "    cwd='/content/project/kyivstar-test-task'\n",
        ")\n",
        "\n",
        "for line in process.stdout:\n",
        "    print(line, end='')\n",
        "\n",
        "return_code = process.wait()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "if return_code != 0:\n",
        "    print(f\"❌ Ошибка! Return code: {return_code}\")"
      ],
      "metadata": {
        "id": "d3aJMUfnrYh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "217e64b1-4c21-4f22-f4d3-b09b650cd89a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-12 17:09:28.142670: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-12 17:09:28.160720: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762967368.181976    2400 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762967368.188444    2400 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762967368.205118    2400 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762967368.205141    2400 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762967368.205143    2400 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762967368.205145    2400 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-12 17:09:28.210213: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-11-12 17:09:34,379 - __main__ - INFO - Configuration loaded from config/config.yaml\n",
            "2025-11-12 17:09:34,379 - __main__ - INFO - Pipeline initialized\n",
            "2025-11-12 17:09:34,379 - __main__ - INFO - \n",
            "====================================================================================================\n",
            "2025-11-12 17:09:34,379 - __main__ - INFO - STARTING CUSTOM PIPELINE\n",
            "2025-11-12 17:09:34,379 - __main__ - INFO - Stages to run: eval\n",
            "2025-11-12 17:09:34,379 - __main__ - INFO - Start time: 2025-11-12 17:09:34\n",
            "2025-11-12 17:09:34,379 - __main__ - INFO - ====================================================================================================\n",
            "\n",
            "2025-11-12 17:09:34,379 - __main__ - INFO - \n",
            "====================================================================================================\n",
            "2025-11-12 17:09:34,379 - __main__ - INFO - STAGE: MODEL EVALUATION\n",
            "2025-11-12 17:09:34,379 - __main__ - INFO - ====================================================================================================\n",
            "\n",
            "2025-11-12 17:09:34,390 - llm_summarize.models_evaluation - INFO - Configuration loaded from config/config.yaml\n",
            "2025-11-12 17:09:35,747 - evaluate_modules.metrics.evaluate-measurement--toxicity.2390290fa0bf6d78480143547c6b08f3d4f8805b249df8c7a8e80d0ce8e3778b.toxicity - WARNING - Using default facebook/roberta-hate-speech-dynabench-r4-target checkpoint\n",
            "Device set to use cuda:0\n",
            "2025-11-12 17:09:36,522 - llm_summarize.models_evaluation - INFO - ModelEvaluator initialized successfully\n",
            "2025-11-12 17:09:36,522 - llm_summarize.models_evaluation - INFO - \n",
            "================================================================================\n",
            "2025-11-12 17:09:36,522 - llm_summarize.models_evaluation - INFO - MODEL EVALUATION PIPELINE\n",
            "2025-11-12 17:09:36,522 - llm_summarize.models_evaluation - INFO - ================================================================================\n",
            "\n",
            "2025-11-12 17:09:36,522 - llm_summarize.models_evaluation - INFO - \n",
            "================================================================================\n",
            "2025-11-12 17:09:36,522 - llm_summarize.models_evaluation - INFO - EVALUATING ALL MODELS\n",
            "2025-11-12 17:09:36,522 - llm_summarize.models_evaluation - INFO - ================================================================================\n",
            "\n",
            "2025-11-12 17:09:36,522 - llm_summarize.models_evaluation - INFO - Loading test data...\n",
            "2025-11-12 17:09:36,538 - llm_summarize.models_evaluation - INFO - Loaded 134 test samples from toxic dataset\n",
            "2025-11-12 17:09:36,539 - llm_summarize.models_evaluation - INFO - Test data ready: 134 samples\n",
            "2025-11-12 17:09:36,539 - llm_summarize.models_evaluation - INFO - \n",
            "================================================================================\n",
            "2025-11-12 17:09:36,539 - llm_summarize.models_evaluation - INFO - Evaluating model: base\n",
            "2025-11-12 17:09:36,539 - llm_summarize.models_evaluation - INFO - ================================================================================\n",
            "\n",
            "2025-11-12 17:09:36,539 - llm_summarize.models_evaluation - INFO - Loading model from google/gemma-3-1b-it...\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "2025-11-12 17:09:38,799 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "2025-11-12 17:09:39,892 - llm_summarize.models_evaluation - INFO - Loaded model from google/gemma-3-1b-it\n",
            "\n",
            "Generating:   0%|          | 0/34 [00:00<?, ?it/s]\n",
            "Generating:   3%|▎         | 1/34 [00:08<04:34,  8.30s/it]\n",
            "Generating:   6%|▌         | 2/34 [00:15<04:13,  7.91s/it]\n",
            "Generating:   9%|▉         | 3/34 [00:23<04:01,  7.79s/it]\n",
            "Generating:  12%|█▏        | 4/34 [00:31<03:52,  7.73s/it]\n",
            "Generating:  15%|█▍        | 5/34 [00:38<03:43,  7.72s/it]\n",
            "Generating:  18%|█▊        | 6/34 [00:46<03:36,  7.73s/it]\n",
            "Generating:  21%|██        | 7/34 [00:54<03:31,  7.85s/it]\n",
            "Generating:  24%|██▎       | 8/34 [01:02<03:22,  7.80s/it]\n",
            "Generating:  26%|██▋       | 9/34 [01:10<03:13,  7.75s/it]\n",
            "Generating:  29%|██▉       | 10/34 [01:17<03:05,  7.72s/it]\n",
            "Generating:  32%|███▏      | 11/34 [01:25<02:57,  7.72s/it]\n",
            "Generating:  35%|███▌      | 12/34 [01:33<02:49,  7.70s/it]\n",
            "Generating:  38%|███▊      | 13/34 [01:40<02:41,  7.71s/it]\n",
            "Generating:  41%|████      | 14/34 [01:48<02:34,  7.71s/it]\n",
            "Generating:  44%|████▍     | 15/34 [01:56<02:26,  7.70s/it]\n",
            "Generating:  47%|████▋     | 16/34 [02:04<02:18,  7.71s/it]\n",
            "Generating:  50%|█████     | 17/34 [02:11<02:10,  7.70s/it]\n",
            "Generating:  53%|█████▎    | 18/34 [02:19<02:03,  7.70s/it]\n",
            "Generating:  56%|█████▌    | 19/34 [02:27<01:55,  7.70s/it]\n",
            "Generating:  59%|█████▉    | 20/34 [02:34<01:47,  7.69s/it]\n",
            "Generating:  62%|██████▏   | 21/34 [02:42<01:40,  7.70s/it]\n",
            "Generating:  65%|██████▍   | 22/34 [02:50<01:32,  7.70s/it]\n",
            "Generating:  68%|██████▊   | 23/34 [02:57<01:24,  7.70s/it]\n",
            "Generating:  71%|███████   | 24/34 [03:05<01:17,  7.72s/it]\n",
            "Generating:  74%|███████▎  | 25/34 [03:13<01:09,  7.72s/it]\n",
            "Generating:  76%|███████▋  | 26/34 [03:21<01:01,  7.72s/it]\n",
            "Generating:  79%|███████▉  | 27/34 [03:28<00:54,  7.73s/it]\n",
            "Generating:  82%|████████▏ | 28/34 [03:36<00:46,  7.73s/it]\n",
            "Generating:  85%|████████▌ | 29/34 [03:44<00:38,  7.72s/it]\n",
            "Generating:  88%|████████▊ | 30/34 [03:52<00:30,  7.73s/it]\n",
            "Generating:  91%|█████████ | 31/34 [03:59<00:23,  7.73s/it]\n",
            "Generating:  94%|█████████▍| 32/34 [04:07<00:15,  7.72s/it]\n",
            "Generating:  97%|█████████▋| 33/34 [04:15<00:07,  7.73s/it]\n",
            "Generating: 100%|██████████| 34/34 [04:22<00:00,  7.72s/it]\n",
            "Generating: 100%|██████████| 34/34 [04:22<00:00,  7.73s/it]\n",
            "2025-11-12 17:14:02,795 - llm_summarize.models_evaluation - INFO - Generated 134 summaries\n",
            "2025-11-12 17:14:02,795 - llm_summarize.models_evaluation - INFO - Computing ROUGE scores...\n",
            "2025-11-12 17:14:02,807 - absl - INFO - Using default tokenizer.\n",
            "2025-11-12 17:14:02,991 - llm_summarize.models_evaluation - INFO - Computing toxicity scores...\n",
            "2025-11-12 17:14:04,415 - llm_summarize.models_evaluation - INFO - \n",
            "Results for base:\n",
            "2025-11-12 17:14:04,415 - llm_summarize.models_evaluation - INFO -   ROUGE-1: 0.0538\n",
            "2025-11-12 17:14:04,415 - llm_summarize.models_evaluation - INFO -   ROUGE-2: 0.0127\n",
            "2025-11-12 17:14:04,415 - llm_summarize.models_evaluation - INFO -   ROUGE-L: 0.0508\n",
            "2025-11-12 17:14:04,415 - llm_summarize.models_evaluation - INFO -   ROUGE-Lsum: 0.0508\n",
            "2025-11-12 17:14:04,415 - llm_summarize.models_evaluation - INFO -   Max Toxicity: 0.2769\n",
            "2025-11-12 17:14:04,415 - llm_summarize.models_evaluation - INFO -   Mean Toxicity: 0.0081\n",
            "2025-11-12 17:14:04,434 - llm_summarize.models_evaluation - INFO - Predictions saved to outputs/base_predictions.jsonl\n",
            "2025-11-12 17:14:04,556 - llm_summarize.models_evaluation - INFO - \n",
            "================================================================================\n",
            "2025-11-12 17:14:04,557 - llm_summarize.models_evaluation - INFO - Evaluating model: sft\n",
            "2025-11-12 17:14:04,558 - llm_summarize.models_evaluation - INFO - ================================================================================\n",
            "\n",
            "2025-11-12 17:14:04,558 - llm_summarize.models_evaluation - INFO - Loading model from models/sft_final...\n",
            "2025-11-12 17:14:06,634 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "2025-11-12 17:14:08,084 - llm_summarize.models_evaluation - INFO - Loaded PEFT model from models/sft_final\n",
            "\n",
            "Generating:   0%|          | 0/34 [00:00<?, ?it/s]\n",
            "Generating:   3%|▎         | 1/34 [00:05<03:10,  5.76s/it]\n",
            "Generating:   6%|▌         | 2/34 [00:10<02:35,  4.87s/it]\n",
            "Generating:   9%|▉         | 3/34 [00:17<03:07,  6.06s/it]\n",
            "Generating:  12%|█▏        | 4/34 [00:23<03:01,  6.05s/it]\n",
            "Generating:  15%|█▍        | 5/34 [00:32<03:23,  7.03s/it]\n",
            "Generating:  18%|█▊        | 6/34 [00:36<02:53,  6.19s/it]\n",
            "Generating:  21%|██        | 7/34 [00:41<02:33,  5.68s/it]\n",
            "Generating:  24%|██▎       | 8/34 [00:45<02:17,  5.30s/it]\n",
            "Generating:  26%|██▋       | 9/34 [00:52<02:21,  5.66s/it]\n",
            "Generating:  29%|██▉       | 10/34 [00:58<02:17,  5.74s/it]\n",
            "Generating:  32%|███▏      | 11/34 [01:04<02:18,  6.01s/it]\n",
            "Generating:  35%|███▌      | 12/34 [01:11<02:13,  6.07s/it]\n",
            "Generating:  38%|███▊      | 13/34 [01:21<02:34,  7.36s/it]\n",
            "Generating:  41%|████      | 14/34 [01:27<02:16,  6.83s/it]\n",
            "Generating:  44%|████▍     | 15/34 [01:32<02:00,  6.35s/it]\n",
            "Generating:  47%|████▋     | 16/34 [01:36<01:44,  5.80s/it]\n",
            "Generating:  50%|█████     | 17/34 [01:42<01:36,  5.67s/it]\n",
            "Generating:  53%|█████▎    | 18/34 [01:48<01:34,  5.93s/it]\n",
            "Generating:  56%|█████▌    | 19/34 [01:57<01:39,  6.64s/it]\n",
            "Generating:  59%|█████▉    | 20/34 [02:01<01:23,  5.97s/it]\n",
            "Generating:  62%|██████▏   | 21/34 [02:06<01:12,  5.59s/it]\n",
            "Generating:  65%|██████▍   | 22/34 [02:12<01:08,  5.74s/it]\n",
            "Generating:  68%|██████▊   | 23/34 [02:19<01:08,  6.26s/it]\n",
            "Generating:  71%|███████   | 24/34 [02:24<00:59,  5.95s/it]\n",
            "Generating:  74%|███████▎  | 25/34 [02:30<00:53,  5.97s/it]\n",
            "Generating:  76%|███████▋  | 26/34 [02:36<00:46,  5.81s/it]\n",
            "Generating:  79%|███████▉  | 27/34 [02:41<00:38,  5.57s/it]\n",
            "Generating:  82%|████████▏ | 28/34 [02:52<00:42,  7.13s/it]\n",
            "Generating:  85%|████████▌ | 29/34 [02:58<00:35,  7.03s/it]\n",
            "Generating:  88%|████████▊ | 30/34 [03:05<00:27,  6.83s/it]\n",
            "Generating:  91%|█████████ | 31/34 [03:11<00:19,  6.54s/it]\n",
            "Generating:  94%|█████████▍| 32/34 [03:16<00:12,  6.26s/it]\n",
            "Generating:  97%|█████████▋| 33/34 [03:24<00:06,  6.68s/it]\n",
            "Generating: 100%|██████████| 34/34 [03:29<00:00,  6.33s/it]\n",
            "Generating: 100%|██████████| 34/34 [03:29<00:00,  6.18s/it]\n",
            "2025-11-12 17:17:38,046 - llm_summarize.models_evaluation - INFO - Generated 134 summaries\n",
            "2025-11-12 17:17:38,047 - llm_summarize.models_evaluation - INFO - Computing ROUGE scores...\n",
            "2025-11-12 17:17:38,053 - absl - INFO - Using default tokenizer.\n",
            "2025-11-12 17:17:38,233 - llm_summarize.models_evaluation - INFO - Computing toxicity scores...\n",
            "2025-11-12 17:17:39,435 - llm_summarize.models_evaluation - INFO - \n",
            "Results for sft:\n",
            "2025-11-12 17:17:39,436 - llm_summarize.models_evaluation - INFO -   ROUGE-1: 0.0445\n",
            "2025-11-12 17:17:39,436 - llm_summarize.models_evaluation - INFO -   ROUGE-2: 0.0224\n",
            "2025-11-12 17:17:39,436 - llm_summarize.models_evaluation - INFO -   ROUGE-L: 0.0444\n",
            "2025-11-12 17:17:39,436 - llm_summarize.models_evaluation - INFO -   ROUGE-Lsum: 0.0428\n",
            "2025-11-12 17:17:39,436 - llm_summarize.models_evaluation - INFO -   Max Toxicity: 0.4006\n",
            "2025-11-12 17:17:39,436 - llm_summarize.models_evaluation - INFO -   Mean Toxicity: 0.0066\n",
            "2025-11-12 17:17:39,450 - llm_summarize.models_evaluation - INFO - Predictions saved to outputs/sft_predictions.jsonl\n",
            "2025-11-12 17:17:39,563 - llm_summarize.models_evaluation - INFO - \n",
            "================================================================================\n",
            "2025-11-12 17:17:39,563 - llm_summarize.models_evaluation - INFO - Evaluating model: grpo\n",
            "2025-11-12 17:17:39,564 - llm_summarize.models_evaluation - INFO - ================================================================================\n",
            "\n",
            "2025-11-12 17:17:39,564 - llm_summarize.models_evaluation - INFO - Loading model from models/grpo_final...\n",
            "2025-11-12 17:17:41,513 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "2025-11-12 17:17:42,998 - llm_summarize.models_evaluation - INFO - Loaded PEFT model from models/grpo_final\n",
            "\n",
            "Generating:   0%|          | 0/34 [00:00<?, ?it/s]\n",
            "Generating:   3%|▎         | 1/34 [00:05<03:07,  5.68s/it]\n",
            "Generating:   6%|▌         | 2/34 [00:12<03:29,  6.56s/it]\n",
            "Generating:   9%|▉         | 3/34 [00:17<02:52,  5.56s/it]\n",
            "Generating:  12%|█▏        | 4/34 [00:21<02:31,  5.03s/it]\n",
            "Generating:  15%|█▍        | 5/34 [00:25<02:19,  4.80s/it]\n",
            "Generating:  18%|█▊        | 6/34 [00:31<02:19,  4.97s/it]\n",
            "Generating:  21%|██        | 7/34 [00:36<02:21,  5.23s/it]\n",
            "Generating:  24%|██▎       | 8/34 [00:42<02:16,  5.25s/it]\n",
            "Generating:  26%|██▋       | 9/34 [00:47<02:10,  5.23s/it]\n",
            "Generating:  29%|██▉       | 10/34 [00:54<02:17,  5.72s/it]\n",
            "Generating:  32%|███▏      | 11/34 [01:02<02:28,  6.47s/it]\n",
            "Generating:  35%|███▌      | 12/34 [01:07<02:12,  6.02s/it]\n",
            "Generating:  38%|███▊      | 13/34 [01:13<02:05,  5.96s/it]\n",
            "Generating:  41%|████      | 14/34 [01:17<01:52,  5.61s/it]\n",
            "Generating:  44%|████▍     | 15/34 [01:22<01:42,  5.37s/it]\n",
            "Generating:  47%|████▋     | 16/34 [01:29<01:43,  5.74s/it]\n",
            "Generating:  50%|█████     | 17/34 [01:35<01:40,  5.90s/it]\n",
            "Generating:  53%|█████▎    | 18/34 [01:41<01:34,  5.93s/it]\n",
            "Generating:  56%|█████▌    | 19/34 [01:47<01:30,  6.04s/it]\n",
            "Generating:  59%|█████▉    | 20/34 [01:54<01:25,  6.08s/it]\n",
            "Generating:  62%|██████▏   | 21/34 [01:58<01:13,  5.65s/it]\n",
            "Generating:  65%|██████▍   | 22/34 [02:05<01:10,  5.84s/it]\n",
            "Generating:  68%|██████▊   | 23/34 [02:12<01:09,  6.32s/it]\n",
            "Generating:  71%|███████   | 24/34 [02:17<00:59,  5.94s/it]\n",
            "Generating:  74%|███████▎  | 25/34 [02:22<00:49,  5.55s/it]\n",
            "Generating:  76%|███████▋  | 26/34 [02:26<00:41,  5.24s/it]\n",
            "Generating:  79%|███████▉  | 27/34 [02:32<00:37,  5.35s/it]\n",
            "Generating:  82%|████████▏ | 28/34 [02:37<00:32,  5.39s/it]\n",
            "Generating:  85%|████████▌ | 29/34 [02:42<00:25,  5.17s/it]\n",
            "Generating:  88%|████████▊ | 30/34 [02:47<00:20,  5.15s/it]\n",
            "Generating:  91%|█████████ | 31/34 [02:53<00:15,  5.26s/it]\n",
            "Generating:  94%|█████████▍| 32/34 [02:58<00:10,  5.28s/it]\n",
            "Generating:  97%|█████████▋| 33/34 [03:03<00:05,  5.13s/it]\n",
            "Generating: 100%|██████████| 34/34 [03:09<00:00,  5.35s/it]\n",
            "Generating: 100%|██████████| 34/34 [03:09<00:00,  5.56s/it]\n",
            "2025-11-12 17:20:52,049 - llm_summarize.models_evaluation - INFO - Generated 134 summaries\n",
            "2025-11-12 17:20:52,049 - llm_summarize.models_evaluation - INFO - Computing ROUGE scores...\n",
            "2025-11-12 17:20:52,056 - absl - INFO - Using default tokenizer.\n",
            "2025-11-12 17:20:52,233 - llm_summarize.models_evaluation - INFO - Computing toxicity scores...\n",
            "2025-11-12 17:20:53,407 - llm_summarize.models_evaluation - INFO - \n",
            "Results for grpo:\n",
            "2025-11-12 17:20:53,407 - llm_summarize.models_evaluation - INFO -   ROUGE-1: 0.0638\n",
            "2025-11-12 17:20:53,407 - llm_summarize.models_evaluation - INFO -   ROUGE-2: 0.0224\n",
            "2025-11-12 17:20:53,407 - llm_summarize.models_evaluation - INFO -   ROUGE-L: 0.0627\n",
            "2025-11-12 17:20:53,408 - llm_summarize.models_evaluation - INFO -   ROUGE-Lsum: 0.0627\n",
            "2025-11-12 17:20:53,408 - llm_summarize.models_evaluation - INFO -   Max Toxicity: 0.1735\n",
            "2025-11-12 17:20:53,408 - llm_summarize.models_evaluation - INFO -   Mean Toxicity: 0.0062\n",
            "2025-11-12 17:20:53,421 - llm_summarize.models_evaluation - INFO - Predictions saved to outputs/grpo_predictions.jsonl\n",
            "2025-11-12 17:20:53,544 - llm_summarize.models_evaluation - INFO - \n",
            "Evaluation results saved to outputs/evaluation_results.csv\n",
            "2025-11-12 17:20:53,544 - llm_summarize.models_evaluation - INFO - \n",
            "================================================================================\n",
            "2025-11-12 17:20:53,544 - llm_summarize.models_evaluation - INFO - EVALUATION SUMMARY\n",
            "2025-11-12 17:20:53,544 - llm_summarize.models_evaluation - INFO - ================================================================================\n",
            "\n",
            "2025-11-12 17:20:53,551 - llm_summarize.models_evaluation - INFO - \n",
            "================================================================================\n",
            "2025-11-12 17:20:53,551 - llm_summarize.models_evaluation - INFO - EVALUATION COMPLETED SUCCESSFULLY\n",
            "2025-11-12 17:20:53,551 - llm_summarize.models_evaluation - INFO - ================================================================================\n",
            "\n",
            "2025-11-12 17:20:53,551 - __main__ - INFO - \n",
            "====================================================================================================\n",
            "2025-11-12 17:20:53,551 - __main__ - INFO - STAGE COMPLETED: MODEL EVALUATION\n",
            "2025-11-12 17:20:53,551 - __main__ - INFO - ====================================================================================================\n",
            "\n",
            "2025-11-12 17:20:53,551 - __main__ - INFO - \n",
            "====================================================================================================\n",
            "2025-11-12 17:20:53,551 - __main__ - INFO - CUSTOM PIPELINE COMPLETED SUCCESSFULLY\n",
            "2025-11-12 17:20:53,551 - __main__ - INFO - End time: 2025-11-12 17:20:53\n",
            "2025-11-12 17:20:53,551 - __main__ - INFO - Total duration: 0:11:19.171654\n",
            "2025-11-12 17:20:53,551 - __main__ - INFO - Stages completed: MODEL EVALUATION\n",
            "2025-11-12 17:20:53,551 - __main__ - INFO - ====================================================================================================\n",
            "\n",
            "model_name           model_path   rouge1   rouge2   rougeL  rougeLsum  max_toxicity  mean_toxicity  num_samples\n",
            "      base google/gemma-3-1b-it 0.053820 0.012687 0.050800   0.050779      0.276903       0.008074          134\n",
            "       sft     models/sft_final 0.044492 0.022388 0.044421   0.042786      0.400643       0.006566          134\n",
            "      grpo    models/grpo_final 0.063806 0.022388 0.062687   0.062687      0.173477       0.006231          134\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "project_dir = '/content/project/kyivstar-test-task'\n",
        "\n",
        "output_path = '/content/drive/MyDrive/kyivstar-test-task_COMPLETED'\n",
        "\n",
        "print(f\"Архивируем директорию: {project_dir}\")\n",
        "print(f\"Целевой архив: {output_path}.zip\")\n",
        "\n",
        "shutil.make_archive(\n",
        "    base_name=output_path,\n",
        "    format='zip',\n",
        "    root_dir=os.path.dirname(project_dir),\n",
        "    base_dir=os.path.basename(project_dir)\n",
        ")\n",
        "\n",
        "print(f\"\\n✓ Архив создан успешно!\")\n",
        "print(f\"Размер архива:\")\n",
        "\n",
        "archive_path = output_path + '.zip'\n",
        "if os.path.exists(archive_path):\n",
        "    size_mb = os.path.getsize(archive_path) / (1024 * 1024)\n",
        "    print(f\"  {archive_path}\")\n",
        "    print(f\"  Размер: {size_mb:.2f} MB\")\n",
        "else:\n",
        "    print(f\"  Ошибка: архив не найден!\")\n",
        "\n",
        "print(\"\\nСодержимое архива (первые 20 файлов):\")\n",
        "import zipfile\n",
        "with zipfile.ZipFile(archive_path, 'r') as zip_ref:\n",
        "    files = zip_ref.namelist()[:20]\n",
        "    for f in files:\n",
        "        print(f\"  - {f}\")\n",
        "    if len(zip_ref.namelist()) > 20:\n",
        "        print(f\"  ... и ещё {len(zip_ref.namelist()) - 20} файлов\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRcx5yHpqtGE",
        "outputId": "62aa25d4-b4d9-45a0-ecd9-c5cbac672a84"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Архивируем директорию: /content/project/kyivstar-test-task\n",
            "Целевой архив: /content/drive/MyDrive/kyivstar-test-task_COMPLETED.zip\n",
            "\n",
            "✓ Архив создан успешно!\n",
            "Размер архива:\n",
            "  /content/drive/MyDrive/kyivstar-test-task_COMPLETED.zip\n",
            "  Размер: 812.77 MB\n",
            "\n",
            "Содержимое архива (первые 20 файлов):\n",
            "  - kyivstar-test-task/\n",
            "  - kyivstar-test-task/checkpoints/\n",
            "  - kyivstar-test-task/config/\n",
            "  - kyivstar-test-task/data/\n",
            "  - kyivstar-test-task/grpo_output/\n",
            "  - kyivstar-test-task/llm_summarize/\n",
            "  - kyivstar-test-task/media/\n",
            "  - kyivstar-test-task/models/\n",
            "  - kyivstar-test-task/notebooks/\n",
            "  - kyivstar-test-task/outputs/\n",
            "  - kyivstar-test-task/scripts/\n",
            "  - kyivstar-test-task/sft_output/\n",
            "  - kyivstar-test-task/pyproject.toml\n",
            "  - kyivstar-test-task/entry_point_as_google_colab.ipynb\n",
            "  - kyivstar-test-task/README.md\n",
            "  - kyivstar-test-task/pipeline.log\n",
            "  - kyivstar-test-task/uv.lock\n",
            "  - kyivstar-test-task/outputs/.ipynb_checkpoints/\n",
            "  - kyivstar-test-task/outputs/grpo_predictions.jsonl\n",
            "  - kyivstar-test-task/outputs/base_predictions.jsonl\n",
            "  ... и ещё 155 файлов\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iAyLSlguqtIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IxsWJjgtqtKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XY_roWnoqtM5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}